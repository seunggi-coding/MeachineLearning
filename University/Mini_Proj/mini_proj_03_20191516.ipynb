{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ccdf2b3",
   "metadata": {},
   "source": [
    "# 워싱턴 킹 카운티 주택 거래 가격"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2088b3cf",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b400b7",
   "metadata": {},
   "source": [
    "## pandas의 read_csv()를 이용해 훈련셋 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd83eb0",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122e1b9",
   "metadata": {},
   "source": [
    "## 예측에 필요 없다고 판단되는 열을 삭제, 타겟값을 가진 부분으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d91f8",
   "metadata": {},
   "source": [
    "housing_prepared = df.drop([\"price\", \"id\",\"date\", \"long\", \"lat\", \"zipcode\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "housing_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779bd6e",
   "metadata": {},
   "source": [
    "housing_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344e884",
   "metadata": {},
   "source": [
    "## k-폴드 CV의 평균을 계산하기 위한 함수를 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9122e",
   "metadata": {},
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949f069",
   "metadata": {},
   "source": [
    "## 선형회귀 모델을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e315533",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779c402",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "housing_prepared = df.drop([\"price\", \"id\",\"date\", \"long\", \"lat\", \"zipcode\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# pycaret의 setup 함수를 사용하여 데이터셋 설정\n",
    "reg_setup = setup(data=df, target='price', session_id=123)\n",
    "\n",
    "# compare_models 함수를 사용하여 모든 가능한 모델을 비교\n",
    "best_model = compare_models(sort='RMSE', n_select=1)\n",
    "\n",
    "# 최적 모델 튜닝 및 결과 출력\n",
    "tuned_model = tune_model(best_model, optimize='RMSE', n_iter=200)\n",
    "\n",
    "# 모델 세부 정보 및 튜닝된 하이퍼파라미터 확인\n",
    "print(tuned_model)\n",
    "\n",
    "tuned_model_scores = cross_val_score(tuned_model, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "tuned_model_scores_rmse_scores = np.sqrt(-tuned_model_scores)\n",
    "display_scores(tuned_model_scores_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58cd98",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "housing_prepared = df.drop([\"price\", \"id\",\"date\", \"long\", \"lat\", \"zipcode\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# pycaret의 setup 함수를 사용하여 데이터셋 설정\n",
    "reg_setup = setup(data=df, target='price', session_id=123)\n",
    "\n",
    "# compare_models 함수를 사용하여 모든 가능한 모델을 비교\n",
    "best_model = compare_models(sort='RMSE', n_select=15)\n",
    "\n",
    "top15 = [rank for rank in best_model]\n",
    "\n",
    "for top in top15:\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "   \n",
    "    # 최적 모델 튜닝 및 결과 출력\n",
    "    tuned_model = tune_model(top, optimize='RMSE', n_iter=300)\n",
    "\n",
    "    # 모델 세부 정보 및 튜닝된 하이퍼파라미터 확인\n",
    "    print(tuned_model)\n",
    "\n",
    "    tuned_model_scores = cross_val_score(tuned_model, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "    tuned_model_scores_rmse_scores = np.sqrt(-tuned_model_scores)\n",
    "    display_scores(tuned_model_scores_rmse_scores)\n",
    "   \n",
    "    print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e9952",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "housing_prepared = df.drop([\"price\", \"id\",\"date\", \"long\", \"lat\", \"zipcode\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = -1, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv = 10)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b400e10",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "housing_prepared = df.drop([\"price\", \"id\", \"date\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = -1, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv = 10)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c7fb7",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor  # XGBoost 모델 추가\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "housing_prepared = df.drop([\"price\", \"id\", \"date\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "xgboost_model = XGBRegressor(\n",
    "    max_depth=3,  # 튜닝이 필요한 하이퍼파라미터는 적절히 조절해주세요.\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    objective='reg:squarederror',  # 회귀 문제의 경우 'reg:squarederror'를 사용합니다.\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "xgboost_scores = cross_val_score(xgboost_model, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "xgboost_rmse_scores = np.sqrt(-xgboost_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(xgboost_rmse_scores)\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1859f5a7",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "housing_prepared = df.drop([\"price\", \"id\", \"date\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# XGBoost 모델 정의\n",
    "xgboost_model = XGBRegressor(objective='reg:squarederror', random_state=0)\n",
    "\n",
    "# 그리드 서치에 사용할 하이퍼파라미터 후보\n",
    "param_grid = {\n",
    "    'max_depth': [None, 3, 5, 7, 9, 15, ],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [30, 50, 100, 200, 250]\n",
    "}\n",
    "\n",
    "# 그리드 서치 객체 생성\n",
    "grid_search = GridSearchCV(estimator=xgboost_model, param_grid=param_grid, \n",
    "                           scoring=\"neg_mean_squared_error\", cv=10, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# 최적의 하이퍼파라미터 및 모델 출력\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)\n",
    "\n",
    "# 최적 모델에 대한 성능 평가\n",
    "grid_search_scores = cross_val_score(grid_search.best_estimator_, housing_prepared, housing_labels, \n",
    "                                     scoring=\"neg_mean_squared_error\", cv=10)\n",
    "grid_search_rmse_scores = np.sqrt(-grid_search_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(grid_search_rmse_scores)\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27160e67",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "housing_prepared = df.drop([\"price\", \"id\", \"date\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# LightGBM 모델 정의\n",
    "lgbm = LGBMRegressor(random_state=0)\n",
    "\n",
    "# 탐색할 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'min_data_in_leaf': [20, 30, 40],\n",
    "    'feature_fraction': [0.8, 1.0],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.1155, 0.2],\n",
    "    'num_leaves': [31, 40, 50]\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(lgbm, param_grid, scoring=\"neg_mean_squared_error\", cv=10, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# 최적 모델에 대한 성능 출력\n",
    "best_model = grid_search.best_estimator_\n",
    "best_scores = cross_val_score(best_model, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "best_rmse_scores = np.sqrt(-best_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(best_rmse_scores)\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71910f",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 특성공학 함수 정의\n",
    "def feature_engineering(data):\n",
    "    # 1. 연도 관련 특성\n",
    "    data['house_age'] = 2023 - data['yr_built']\n",
    "    data['years_since_renovation'] = 2023 - data['yr_renovated']\n",
    "\n",
    "    # 2. 면적 관련 특성\n",
    "    data['indoor_to_outdoor_ratio'] = data['sqft_living'] / data['sqft_lot']\n",
    "    data['basement_to_living_ratio'] = data['sqft_basement'] / data['sqft_living']\n",
    "\n",
    "    # 3. 위치 관련 특성\n",
    "    # (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "    data['location'] = data['lat'] + data['long']\n",
    "\n",
    "    # 4. 각종 비율 관련 특성\n",
    "    data['bedrooms_to_bathrooms_ratio'] = data['bedrooms'] / data['bathrooms']\n",
    "    data['living_to_floors_ratio'] = data['sqft_living'] / data['floors']\n",
    "\n",
    "    # 5. 우편번호 관련 특성\n",
    "    # (이 예시에서는 단순히 우편번호를 이용하여 평균 가격을 나타냄)\n",
    "    zipcode_prices = data.groupby('zipcode')['price'].mean().to_dict()\n",
    "    data['average_price_by_zipcode'] = data['zipcode'].map(zipcode_prices)\n",
    "    \n",
    "    # 6. 태원1\n",
    "    data['div_sqft_living_waterfront'] = data['sqft_living'] / data['waterfront'] / 2\n",
    "    \n",
    "    # 7. 태원2\n",
    "    data['sum_sqft_living_waterfront'] = data['sqft_living'] + data['waterfront']\n",
    "\n",
    "    # 8. 태원3\n",
    "    data['sum_sqft_living_yr_renovated'] = data['sqft_living'] + data['yr_renovated']\n",
    "    \n",
    "    # 9. 태원4\n",
    "    data['div_sqft_living_yr_renovated'] = data['sqft_living'] / data['yr_renovated'] / 2\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 특성공학 적용\n",
    "df = feature_engineering(df)\n",
    "\n",
    "# 결측치가 있는 열 삭제\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "housing_prepared = df.drop([\"price\", \"id\", \"date\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "# LightGBM 모델 정의\n",
    "lgbm = LGBMRegressor(random_state=0)\n",
    "\n",
    "# 탐색할 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'min_data_in_leaf': [20, 30, 40],\n",
    "    'feature_fraction': [0.8, 1.0],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.1155, 0.2],\n",
    "    'num_leaves': [31, 40, 50]\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(lgbm, param_grid, scoring=\"neg_mean_squared_error\", cv=10, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# 최적 모델에 대한 성능 출력\n",
    "best_model = grid_search.best_estimator_\n",
    "best_scores = cross_val_score(best_model, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "best_rmse_scores = np.sqrt(-best_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(best_rmse_scores)\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bafb093",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 특성공학 함수 정의\n",
    "def feature_engineering(data):\n",
    "    # 1. 연도 관련 특성\n",
    "    data['house_age'] = 2023 - data['yr_built']\n",
    "    data['years_since_renovation'] = 2023 - data['yr_renovated']\n",
    "\n",
    "    # 2. 면적 관련 특성\n",
    "    data['indoor_to_outdoor_ratio'] = data['sqft_living'] / data['sqft_lot']\n",
    "    data['basement_to_living_ratio'] = data['sqft_basement'] / data['sqft_living']\n",
    "\n",
    "    # 3. 위치 관련 특성\n",
    "    # (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "    data['location'] = data['lat'] + data['long']\n",
    "\n",
    "    # 4. 각종 비율 관련 특성\n",
    "    data['bedrooms_to_bathrooms_ratio'] = data['bedrooms'] / data['bathrooms']\n",
    "    data['living_to_floors_ratio'] = data['sqft_living'] / data['floors']\n",
    "\n",
    "    # 5. 우편번호 관련 특성\n",
    "    # (이 예시에서는 단순히 우편번호를 이용하여 평균 가격을 나타냄)\n",
    "    zipcode_prices = data.groupby('zipcode')['price'].mean().to_dict()\n",
    "    data['average_price_by_zipcode'] = data['zipcode'].map(zipcode_prices)\n",
    "    \n",
    "    # 6. 태원1\n",
    "    data['div_sqft_living_waterfront'] = data['sqft_living'] / data['waterfront'] / 2\n",
    "    \n",
    "    # 7. 태원2\n",
    "    data['sum_sqft_living_waterfront'] = data['sqft_living'] + data['waterfront']\n",
    "\n",
    "    # 8. 태원3\n",
    "    data['sum_sqft_living_yr_renovated'] = data['sqft_living'] + data['yr_renovated']\n",
    "    \n",
    "    # 9. 태원4\n",
    "    data['div_sqft_living_yr_renovated'] = data['sqft_living'] / data['yr_renovated'] / 2\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 특성공학 적용\n",
    "df = feature_engineering(df)\n",
    "\n",
    "# Check and handle infinite or large values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN values\n",
    "\n",
    "# Check the target variable\n",
    "print(df['price'].describe())\n",
    "\n",
    "# Prepare data for modeling\n",
    "housing_prepared = df.drop([\"price\", \"id\", \"date\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# PyCaret setup\n",
    "reg_setup = setup(data=df, target='price', ignore_features=['id'])\n",
    "\n",
    "# Compare models\n",
    "best_model = compare_models(fold=10, sort='RMSE')\n",
    "\n",
    "# Tune the best model\n",
    "tuned_model = tune_model(best_model, fold=10, n_iter=500)\n",
    "\n",
    "# Display summary information for the tuned model\n",
    "print(tuned_model)\n",
    "\n",
    "# Function to display cross-validation scores\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# Fit the tuned model\n",
    "tuned_model.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# Evaluate the tuned model using cross-validation\n",
    "best_scores = cross_val_score(tuned_model, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "best_rmse_scores = np.sqrt(-best_scores)\n",
    "\n",
    "# Display the performance metrics\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(best_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b5a3b0",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 특성공학 함수 정의\n",
    "def feature_engineering(data):\n",
    "    # 1. 연도 관련 특성\n",
    "    data['house_age'] = 2023 - data['yr_built']\n",
    "    data['years_since_renovation'] = 2023 - data['yr_renovated']\n",
    "\n",
    "    # 2. 면적 관련 특성\n",
    "    data['indoor_to_outdoor_ratio'] = data['sqft_living'] / data['sqft_lot']\n",
    "    data['basement_to_living_ratio'] = data['sqft_basement'] / data['sqft_living']\n",
    "\n",
    "    # 3. 위치 관련 특성\n",
    "    # (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "    data['location'] = data['lat'] + data['long']\n",
    "\n",
    "    # 4. 각종 비율 관련 특성\n",
    "    data['bedrooms_to_bathrooms_ratio'] = data['bedrooms'] / data['bathrooms']\n",
    "    data['living_to_floors_ratio'] = data['sqft_living'] / data['floors']\n",
    "\n",
    "    # 5. 우편번호 관련 특성\n",
    "    # (이 예시에서는 단순히 우편번호를 이용하여 평균 가격을 나타냄)\n",
    "    zipcode_prices = data.groupby('zipcode')['price'].mean().to_dict()\n",
    "    data['average_price_by_zipcode'] = data['zipcode'].map(zipcode_prices)\n",
    "    \n",
    "    # 6. 태원1\n",
    "    data['div_sqft_living_waterfront'] = data['sqft_living'] / data['waterfront'] / 2\n",
    "    \n",
    "    # 7. 태원2\n",
    "    data['sum_sqft_living_waterfront'] = data['sqft_living'] + data['waterfront']\n",
    "\n",
    "    # 8. 태원3\n",
    "    data['sum_sqft_living_yr_renovated'] = data['sqft_living'] + data['yr_renovated']\n",
    "    \n",
    "    # 9. 태원4\n",
    "    data['div_sqft_living_yr_renovated'] = data['sqft_living'] / data['yr_renovated'] / 2\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 특성공학 적용\n",
    "df = feature_engineering(df)\n",
    "\n",
    "# Check and handle infinite or large values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)  # Drop rows with NaN values\n",
    "\n",
    "# Check the target variable\n",
    "print(df['price'].describe())\n",
    "\n",
    "# Prepare data for modeling\n",
    "housing_prepared = df.drop([\"price\", \"id\", \"date\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# PyCaret setup\n",
    "reg_setup = setup(data=df, target='price', ignore_features=['id', 'date'])\n",
    "\n",
    "# Compare models\n",
    "best_model = compare_models(fold=10, sort='RMSE')\n",
    "\n",
    "# Tune the best model\n",
    "tuned_model = tune_model(best_model, fold=10, n_iter=500)\n",
    "\n",
    "# Display summary information for the tuned model\n",
    "print(tuned_model)\n",
    "\n",
    "# Function to display cross-validation scores\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# Fit the tuned model\n",
    "tuned_model.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# Evaluate the tuned model using cross-validation\n",
    "best_scores = cross_val_score(tuned_model, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "best_rmse_scores = np.sqrt(-best_scores)\n",
    "\n",
    "# Display the performance metrics\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(best_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f16c828",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from pycaret.regression import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 특성공학 함수 정의\n",
    "def feature_engineering(data):\n",
    "    # 1. 연도 관련 특성\n",
    "    data['house_age'] = 2023 - data['yr_built']\n",
    "    data['years_since_renovation'] = 2023 - data['yr_renovated']\n",
    "\n",
    "    # 2. 면적 관련 특성\n",
    "    data['indoor_to_outdoor_ratio'] = data['sqft_living'] / data['sqft_lot']\n",
    "    data['basement_to_living_ratio'] = data['sqft_basement'] / data['sqft_living']\n",
    "\n",
    "    # 3. 위치 관련 특성\n",
    "    # (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "    data['location'] = data['lat'] + data['long']\n",
    "\n",
    "    # 4. 각종 비율 관련 특성\n",
    "    data['bedrooms_to_bathrooms_ratio'] = data['bedrooms'] / data['bathrooms']\n",
    "    data['living_to_floors_ratio'] = data['sqft_living'] / data['floors']\n",
    "\n",
    "    # 5. 우편번호 관련 특성\n",
    "    # (이 예시에서는 단순히 우편번호를 이용하여 평균 가격을 나타냄)\n",
    "    zipcode_prices = data.groupby('zipcode')['price'].mean().to_dict()\n",
    "    data['average_price_by_zipcode'] = data['zipcode'].map(zipcode_prices)\n",
    "    \n",
    "    # 6. 태원1\n",
    "    data['div_sqft_living_waterfront'] = data['sqft_living'] / data['waterfront'] / 2\n",
    "    \n",
    "    # 7. 태원2\n",
    "    data['sum_sqft_living_waterfront'] = data['sqft_living'] + data['waterfront']\n",
    "\n",
    "    # 8. 태원3\n",
    "    data['sum_sqft_living_yr_renovated'] = data['sqft_living'] + data['yr_renovated']\n",
    "    \n",
    "    # 9. 태원4\n",
    "    data['div_sqft_living_yr_renovated'] = data['sqft_living'] / data['yr_renovated'] / 2\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 특성공학 적용\n",
    "df = feature_engineering(df)\n",
    "\n",
    "housing_prepared = df.drop([\"price\", \"id\", \"date\"], axis=1)\n",
    "housing_labels = df[\"price\"].copy()\n",
    "\n",
    "# LightGBM 모델 정의\n",
    "lgbm = LGBMRegressor(random_state=0)\n",
    "\n",
    "# Extra Trees 모델 정의\n",
    "extratree = ExtraTreesRegressor(random_state=0)\n",
    "\n",
    "# VotingRegressor 정의\n",
    "voting_regressor = VotingRegressor(estimators=[('lgbm', lgbm), ('extratree', extratree)])\n",
    "\n",
    "# VotingRegressor에 대한 탐색할 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'lgbm__max_depth': [-1, 10, 20],\n",
    "    'lgbm__min_data_in_leaf': [20, 30, 40],\n",
    "    'lgbm__feature_fraction': [0.8, 1.0],\n",
    "    'lgbm__n_estimators': [50, 100, 200],\n",
    "    'lgbm__learning_rate': [0.1, 0.1155, 0.2],\n",
    "    'lgbm__num_leaves': [31, 40, 50],\n",
    "    \n",
    "    'extratree__n_estimators': [50, 100, 200],\n",
    "    'extratree__max_depth': [None, 10, 20],\n",
    "    'extratree__min_samples_split': [2, 5, 10],\n",
    "    'extratree__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(voting_regressor, param_grid, scoring=\"neg_mean_squared_error\", cv=10, verbose=2, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치 수행\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# 최적 모델에 대한 성능 출력\n",
    "best_model = grid_search.best_estimator_\n",
    "best_scores = cross_val_score(best_model, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "best_rmse_scores = np.sqrt(-best_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(best_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d047e8c",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# # 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'] )\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1/(housing_train[\"sqft_living\"]+housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living']*housing_train['grade'])/2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "housing_train = housing_train[housing_train['bedrooms'] != 8]\n",
    "\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"years_since_renovation\"]<500].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"view\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"Totalviews\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"condition\"]<0.3].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"sqft_basement\"]>470].index, axis=0)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bathrooms'])\n",
    "max_distance = np.std(housing_train['bathrooms']) * 3 \n",
    "\n",
    "for idx, row in housing_train['bathrooms'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['grade'])\n",
    "max_distance = np.std(housing_train['grade']) * 3\n",
    "\n",
    "for idx, row in housing_train['grade'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms'])\n",
    "max_distance = np.std(housing_train['bedrooms']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_living'])\n",
    "max_distance = np.std(housing_train['sqft_living']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_living'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot'])\n",
    "max_distance = np.std(housing_train['sqft_lot']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['(sqft_living*grade)/2'])\n",
    "max_distance = np.std(housing_train['(sqft_living*grade)/2']) * 3\n",
    "\n",
    "for idx, row in housing_train['(sqft_living*grade)/2'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot15'])\n",
    "max_distance = np.std(housing_train['sqft_lot15']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot15'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms_to_bathrooms_ratio'])\n",
    "max_distance = np.std(housing_train['bedrooms_to_bathrooms_ratio']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms_to_bathrooms_ratio'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['condition'])\n",
    "max_distance = np.std(housing_train['condition']) * 3\n",
    "\n",
    "for idx, row in housing_train['condition'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.dropna()\n",
    "filtered_train_data = filtered_train_data.drop(\"date\", axis=1)\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "#filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "corr_matrix = housing_train.corr()\n",
    "corr_matrix[\"price\"].sort_values(ascending=False)\n",
    "\n",
    "filtered_train_data = filtered_train_data.drop('waterfront',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('yr_renovated',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('years_since_renovation',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('Totalviews',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_day_name',axis=1)\n",
    "\n",
    "filtered_train_data['t1'] = filtered_train_data['zipcode']**2 * np.log(np.where(filtered_train_data['yr_built'] != 0, filtered_train_data['yr_built'], 1))\n",
    "filtered_train_data['t3'] = filtered_train_data['lat']**2 * filtered_train_data['long']**3\n",
    "filtered_train_data['t4'] = filtered_train_data['bathrooms']**3 * filtered_train_data['sqft_lot']\n",
    "filtered_train_data['t5'] = filtered_train_data['sqft_living15']**2 / np.sqrt(filtered_train_data['sqft_lot15'])\n",
    "filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = -1, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7e81d6",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# # 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'] )\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1/(housing_train[\"sqft_living\"]+housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living']*housing_train['grade'])/2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "housing_train = housing_train[housing_train['bedrooms'] != 8]\n",
    "\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"years_since_renovation\"]<500].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"view\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"Totalviews\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"condition\"]<0.3].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"sqft_basement\"]>470].index, axis=0)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bathrooms'])\n",
    "max_distance = np.std(housing_train['bathrooms']) * 3 \n",
    "\n",
    "for idx, row in housing_train['bathrooms'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['grade'])\n",
    "max_distance = np.std(housing_train['grade']) * 3\n",
    "\n",
    "for idx, row in housing_train['grade'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms'])\n",
    "max_distance = np.std(housing_train['bedrooms']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_living'])\n",
    "max_distance = np.std(housing_train['sqft_living']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_living'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot'])\n",
    "max_distance = np.std(housing_train['sqft_lot']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['(sqft_living*grade)/2'])\n",
    "max_distance = np.std(housing_train['(sqft_living*grade)/2']) * 3\n",
    "\n",
    "for idx, row in housing_train['(sqft_living*grade)/2'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot15'])\n",
    "max_distance = np.std(housing_train['sqft_lot15']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot15'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms_to_bathrooms_ratio'])\n",
    "max_distance = np.std(housing_train['bedrooms_to_bathrooms_ratio']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms_to_bathrooms_ratio'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['condition'])\n",
    "max_distance = np.std(housing_train['condition']) * 3\n",
    "\n",
    "for idx, row in housing_train['condition'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.dropna()\n",
    "filtered_train_data = filtered_train_data.drop(\"date\", axis=1)\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "#filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "corr_matrix = housing_train.corr()\n",
    "corr_matrix[\"price\"].sort_values(ascending=False)\n",
    "\n",
    "filtered_train_data = filtered_train_data.drop('waterfront',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('yr_renovated',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('years_since_renovation',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('Totalviews',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_day_name',axis=1)\n",
    "\n",
    "filtered_train_data['t1'] = filtered_train_data['zipcode']**2 * np.log(filtered_train_data['yr_built'])\n",
    "filtered_train_data['t3'] = filtered_train_data['lat']**2 * filtered_train_data['long']**3\n",
    "filtered_train_data['t4'] = filtered_train_data['bathrooms']**3 * filtered_train_data['sqft_lot']\n",
    "filtered_train_data['t5'] = filtered_train_data['sqft_living15']**2 / np.sqrt(filtered_train_data['sqft_lot15'])\n",
    "filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = -1, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3183f",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor, ExtraTreesRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "print(\"특성공학 시작\")\n",
    "# 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'] )\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1/(housing_train[\"sqft_living\"]+housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living']*housing_train['grade'])/2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "housing_train = housing_train[housing_train['bedrooms'] != 8]\n",
    "\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"years_since_renovation\"]<500].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"view\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"Totalviews\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"condition\"]<0.3].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"sqft_basement\"]>470].index, axis=0)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bathrooms'])\n",
    "max_distance = np.std(housing_train['bathrooms']) * 3 \n",
    "\n",
    "for idx, row in housing_train['bathrooms'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['grade'])\n",
    "max_distance = np.std(housing_train['grade']) * 3\n",
    "\n",
    "for idx, row in housing_train['grade'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms'])\n",
    "max_distance = np.std(housing_train['bedrooms']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_living'])\n",
    "max_distance = np.std(housing_train['sqft_living']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_living'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot'])\n",
    "max_distance = np.std(housing_train['sqft_lot']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['(sqft_living*grade)/2'])\n",
    "max_distance = np.std(housing_train['(sqft_living*grade)/2']) * 3\n",
    "\n",
    "for idx, row in housing_train['(sqft_living*grade)/2'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot15'])\n",
    "max_distance = np.std(housing_train['sqft_lot15']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot15'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms_to_bathrooms_ratio'])\n",
    "max_distance = np.std(housing_train['bedrooms_to_bathrooms_ratio']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms_to_bathrooms_ratio'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['condition'])\n",
    "max_distance = np.std(housing_train['condition']) * 3\n",
    "\n",
    "for idx, row in housing_train['condition'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.dropna()\n",
    "filtered_train_data = filtered_train_data.drop(\"date\", axis=1)\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "#filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "corr_matrix = housing_train.corr()\n",
    "corr_matrix[\"price\"].sort_values(ascending=False)\n",
    "\n",
    "filtered_train_data = filtered_train_data.drop('waterfront',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('yr_renovated',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('years_since_renovation',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('Totalviews',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_day_name',axis=1)\n",
    "\n",
    "filtered_train_data['t1'] = filtered_train_data['zipcode']**2 * np.log(filtered_train_data['yr_built'])\n",
    "filtered_train_data['t3'] = filtered_train_data['lat']**2 * filtered_train_data['long']**3\n",
    "filtered_train_data['t4'] = filtered_train_data['bathrooms']**3 * filtered_train_data['sqft_lot']\n",
    "filtered_train_data['t5'] = filtered_train_data['sqft_living15']**2 / np.sqrt(filtered_train_data['sqft_lot15'])\n",
    "filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "print(\"특성공학 종료\")\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace infinity with NaN\n",
    "sh_t_data = np.where(np.isinf(sh_t_data), np.nan, sh_t_data)\n",
    "\n",
    "# Calculate mean for each column (ignoring NaN values)\n",
    "column_means = np.nanmean(sh_t_data, axis=0)\n",
    "\n",
    "# Create an imputer that replaces NaN with the mean for each column\n",
    "imputer = SimpleImputer(strategy=\"mean\", missing_values=np.nan)\n",
    "sh_t_data = imputer.fit_transform(sh_t_data)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sh_t_data_scaled = scaler.fit_transform(sh_t_data)\n",
    "\n",
    "# 그리드 서치를 위한 ExtraTreesRegressor 하이퍼파라미터 그리드\n",
    "et_param_grid = {\n",
    "    'n_estimators': [20, 50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 4, 6, 8],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "print(\"Extratree 그리드 서치 진행\")\n",
    "# ExtraTreesRegressor 그리드 서치 객체 생성\n",
    "et_grid_search = GridSearchCV(ExtraTreesRegressor(random_state=0), et_param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "et_grid_search.fit(sh_t_data_scaled, sh_t_target)\n",
    "print(\"Extratree 그리드 서치 종료\")\n",
    "\n",
    "# 최적의 ExtraTreesRegressor 모델\n",
    "best_et_model = et_grid_search.best_estimator_\n",
    "print(f\"best_et_model: {best_et_model}\")\n",
    "\n",
    "# LGBMRegressor 그리드 서치를 위한 하이퍼파라미터 그리드\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.03, 0.1, 0.2],\n",
    "    'num_leaves': [20, 30, 40, 50],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "}\n",
    "\n",
    "print(\"LGBM 그리드 서치 진행\")\n",
    "# LGBMRegressor 그리드 서치 객체 생성\n",
    "lgbm_grid_search = GridSearchCV(LGBMRegressor(random_state=0), lgbm_param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "lgbm_grid_search.fit(sh_t_data_scaled, sh_t_target)\n",
    "print(\"LGBM 그리드 서치 종료\")\n",
    "\n",
    "# 최적의 LGBMRegressor 모델\n",
    "best_lgbm_model = lgbm_grid_search.best_estimator_\n",
    "print(f\"best_lgbm_model: {best_lgbm_model}\")\n",
    "\n",
    "# VotingRegressor 생성\n",
    "voting_regressor = VotingRegressor(\n",
    "    estimators=[('et', best_et_model), ('lgbm', best_lgbm_model)]\n",
    ")\n",
    "\n",
    "# VotingRegressor 학습\n",
    "voting_regressor.fit(sh_t_data_scaled, sh_t_target)\n",
    "\n",
    "# VotingRegressor의 성능 평가\n",
    "voting_scores = cross_val_score(voting_regressor, sh_t_data_scaled, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "voting_rmse_scores = np.sqrt(-voting_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "print(\"Voting Regressor Scores:\")\n",
    "display_scores(voting_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb4b5d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor, ExtraTreesRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "print(\"특성공학 시작\")\n",
    "# 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'] )\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1/(housing_train[\"sqft_living\"]+housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living']*housing_train['grade'])/2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "housing_train = housing_train[housing_train['bedrooms'] != 8]\n",
    "\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"years_since_renovation\"]<500].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"view\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"Totalviews\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"condition\"]<0.3].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"sqft_basement\"]>470].index, axis=0)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bathrooms'])\n",
    "max_distance = np.std(housing_train['bathrooms']) * 3 \n",
    "\n",
    "for idx, row in housing_train['bathrooms'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['grade'])\n",
    "max_distance = np.std(housing_train['grade']) * 3\n",
    "\n",
    "for idx, row in housing_train['grade'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms'])\n",
    "max_distance = np.std(housing_train['bedrooms']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_living'])\n",
    "max_distance = np.std(housing_train['sqft_living']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_living'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot'])\n",
    "max_distance = np.std(housing_train['sqft_lot']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['(sqft_living*grade)/2'])\n",
    "max_distance = np.std(housing_train['(sqft_living*grade)/2']) * 3\n",
    "\n",
    "for idx, row in housing_train['(sqft_living*grade)/2'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot15'])\n",
    "max_distance = np.std(housing_train['sqft_lot15']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot15'].items():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms_to_bathrooms_ratio'])\n",
    "max_distance = np.std(housing_train['bedrooms_to_bathrooms_ratio']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms_to_bathrooms_ratio'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['condition'])\n",
    "max_distance = np.std(housing_train['condition']) * 3\n",
    "\n",
    "for idx, row in housing_train['condition'].items():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.dropna()\n",
    "filtered_train_data = filtered_train_data.drop(\"date\", axis=1)\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "#filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "corr_matrix = housing_train.corr()\n",
    "corr_matrix[\"price\"].sort_values(ascending=False)\n",
    "\n",
    "filtered_train_data = filtered_train_data.drop('waterfront',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('yr_renovated',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('years_since_renovation',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('Totalviews',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_day_name',axis=1)\n",
    "\n",
    "filtered_train_data['t1'] = filtered_train_data['zipcode']**2 * np.log(filtered_train_data['yr_built'])\n",
    "filtered_train_data['t3'] = filtered_train_data['lat']**2 * filtered_train_data['long']**3\n",
    "filtered_train_data['t4'] = filtered_train_data['bathrooms']**3 * filtered_train_data['sqft_lot']\n",
    "filtered_train_data['t5'] = filtered_train_data['sqft_living15']**2 / np.sqrt(filtered_train_data['sqft_lot15'])\n",
    "filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "print(\"특성공학 종료\")\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace infinity with NaN\n",
    "sh_t_data = np.where(np.isinf(sh_t_data), np.nan, sh_t_data)\n",
    "\n",
    "# Calculate mean for each column (ignoring NaN values)\n",
    "column_means = np.nanmean(sh_t_data, axis=0)\n",
    "\n",
    "# Create an imputer that replaces NaN with the mean for each column\n",
    "imputer = SimpleImputer(strategy=\"mean\", missing_values=np.nan)\n",
    "sh_t_data = imputer.fit_transform(sh_t_data)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sh_t_data_scaled = scaler.fit_transform(sh_t_data)\n",
    "\n",
    "# 그리드 서치를 위한 ExtraTreesRegressor 하이퍼파라미터 그리드\n",
    "et_param_grid = {\n",
    "    'n_estimators': [20, 30, 50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 4, 6, 8, 12],\n",
    "    'min_samples_leaf': [1, 2, 4, 8]\n",
    "}\n",
    "\n",
    "print(\"Extratree 그리드 서치 진행\")\n",
    "# ExtraTreesRegressor 그리드 서치 객체 생성\n",
    "et_grid_search = GridSearchCV(ExtraTreesRegressor(random_state=0), et_param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "et_grid_search.fit(sh_t_data_scaled, sh_t_target)\n",
    "print(\"Extratree 그리드 서치 종료\")\n",
    "\n",
    "# 최적의 ExtraTreesRegressor 모델\n",
    "best_et_model = et_grid_search.best_estimator_\n",
    "print(f\"best_et_model: {best_et_model}\")\n",
    "\n",
    "# LGBMRegressor 그리드 서치를 위한 하이퍼파라미터 그리드\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2],\n",
    "    'num_leaves': [20, 30, 40, 50, 80, 100],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "}\n",
    "\n",
    "print(\"LGBM 그리드 서치 진행\")\n",
    "# LGBMRegressor 그리드 서치 객체 생성\n",
    "lgbm_grid_search = GridSearchCV(LGBMRegressor(random_state=0), lgbm_param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "lgbm_grid_search.fit(sh_t_data_scaled, sh_t_target)\n",
    "print(\"LGBM 그리드 서치 종료\")\n",
    "\n",
    "# 최적의 LGBMRegressor 모델\n",
    "best_lgbm_model = lgbm_grid_search.best_estimator_\n",
    "print(f\"best_lgbm_model: {best_lgbm_model}\")\n",
    "\n",
    "# VotingRegressor 생성\n",
    "voting_regressor = VotingRegressor(\n",
    "    estimators=[('et', best_et_model), ('lgbm', best_lgbm_model)]\n",
    ")\n",
    "\n",
    "# VotingRegressor 학습\n",
    "voting_regressor.fit(sh_t_data_scaled, sh_t_target)\n",
    "\n",
    "# VotingRegressor의 성능 평가\n",
    "voting_scores = cross_val_score(voting_regressor, sh_t_data_scaled, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "voting_rmse_scores = np.sqrt(-voting_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "print(\"Voting Regressor Scores:\")\n",
    "display_scores(voting_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e5a67",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "# housing_train = housing_train.drop(\"date\", axis=1)\n",
    "\n",
    "# # 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'] )\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1/(housing_train[\"sqft_living\"]+housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living']*housing_train['grade'])/2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "housing_train = housing_train[housing_train['bedrooms'] != 8]\n",
    "\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"years_since_renovation\"]<500].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"view\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"Totalviews\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"condition\"]<0.3].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"sqft_basement\"]>470].index, axis=0)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bathrooms'])\n",
    "max_distance = np.std(housing_train['bathrooms']) * 3 \n",
    "\n",
    "for idx, row in housing_train['bathrooms'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['grade'])\n",
    "max_distance = np.std(housing_train['grade']) * 3\n",
    "\n",
    "for idx, row in housing_train['grade'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms'])\n",
    "max_distance = np.std(housing_train['bedrooms']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_living'])\n",
    "max_distance = np.std(housing_train['sqft_living']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_living'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot'])\n",
    "max_distance = np.std(housing_train['sqft_lot']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['(sqft_living*grade)/2'])\n",
    "max_distance = np.std(housing_train['(sqft_living*grade)/2']) * 3\n",
    "\n",
    "for idx, row in housing_train['(sqft_living*grade)/2'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot15'])\n",
    "max_distance = np.std(housing_train['sqft_lot15']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot15'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms_to_bathrooms_ratio'])\n",
    "max_distance = np.std(housing_train['bedrooms_to_bathrooms_ratio']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms_to_bathrooms_ratio'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['condition'])\n",
    "max_distance = np.std(housing_train['condition']) * 3\n",
    "\n",
    "for idx, row in housing_train['condition'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "housing_train=housing_train[housing_train['bedrooms']!=33]\n",
    "\n",
    "def remove_outliers(df):\n",
    "    '''removes entries with z-score above 3 for specific columns'''\n",
    "    variables = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', \n",
    "                 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "    \n",
    "    for variable in variables:\n",
    "        df = df[np.abs(df[variable]-df[variable].mean()) <= (3*df[variable].std())]\n",
    "        \n",
    "    return df\n",
    "\n",
    "housing_train = remove_outliers(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.dropna()\n",
    "filtered_train_data = filtered_train_data.drop(\"date\", axis=1)\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "#filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "filtered_train_data['t5'] = filtered_train_data['sqft_living15']**2 / np.sqrt(filtered_train_data['sqft_lot15'])\n",
    "filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "corr_matrix = housing_train.corr()\n",
    "corr_matrix[\"price\"].sort_values(ascending=False)\n",
    "\n",
    "filtered_train_data = filtered_train_data.drop('waterfront',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('yr_renovated',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('years_since_renovation',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('Totalviews',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_day_name',axis=1)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = -1, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm.fit(sh_t_data, sh_t_target)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=4)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ea798",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "# housing_train = housing_train.drop(\"date\", axis=1)\n",
    "\n",
    "# # 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'] )\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1/(housing_train[\"sqft_living\"]+housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living']*housing_train['grade'])/2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "housing_train = housing_train[housing_train['bedrooms'] != 8]\n",
    "\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"years_since_renovation\"]<500].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"view\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"Totalviews\"]>0.5].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"condition\"]<0.3].index, axis=0)\n",
    "housing_train = housing_train.drop(housing_train[housing_train[\"sqft_basement\"]>470].index, axis=0)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bathrooms'])\n",
    "max_distance = np.std(housing_train['bathrooms']) * 3 \n",
    "\n",
    "for idx, row in housing_train['bathrooms'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['grade'])\n",
    "max_distance = np.std(housing_train['grade']) * 3\n",
    "\n",
    "for idx, row in housing_train['grade'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms'])\n",
    "max_distance = np.std(housing_train['bedrooms']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_living'])\n",
    "max_distance = np.std(housing_train['sqft_living']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_living'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot'])\n",
    "max_distance = np.std(housing_train['sqft_lot']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['(sqft_living*grade)/2'])\n",
    "max_distance = np.std(housing_train['(sqft_living*grade)/2']) * 3\n",
    "\n",
    "for idx, row in housing_train['(sqft_living*grade)/2'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['sqft_lot15'])\n",
    "max_distance = np.std(housing_train['sqft_lot15']) * 3\n",
    "\n",
    "for idx, row in housing_train['sqft_lot15'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance:\n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['bedrooms_to_bathrooms_ratio'])\n",
    "max_distance = np.std(housing_train['bedrooms_to_bathrooms_ratio']) * 3\n",
    "\n",
    "for idx, row in housing_train['bedrooms_to_bathrooms_ratio'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "count = 0\n",
    "bath_outliers = []\n",
    "mean = np.mean(housing_train['condition'])\n",
    "max_distance = np.std(housing_train['condition']) * 3\n",
    "\n",
    "for idx, row in housing_train['condition'].T.iteritems():\n",
    "    if abs(row-mean) >= max_distance: \n",
    "        count += 1\n",
    "        housing_train.drop(idx, inplace=True)\n",
    "count\n",
    "\n",
    "housing_train=housing_train[housing_train['bedrooms']!=33]\n",
    "\n",
    "# Z-스코어를 계산하여 이상치 및 무한대 값을 제거하는 함수\n",
    "def remove_outliers_zscore(df, features, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df[features]))\n",
    "    outlier_mask = (z_scores > threshold).any(axis=1)\n",
    "    df_cleaned = df[~outlier_mask]\n",
    "    return df_cleaned\n",
    "\n",
    "# 위에서 정의한 함수를 사용하여 이상치 및 무한대 값을 제거\n",
    "features_to_check = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', \n",
    "                      'lat', 'long', 'sqft_living15', 'sqft_lot15', '(sqft_living*grade)/2']\n",
    "\n",
    "housing_train = remove_outliers_zscore(housing_train, features_to_check)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.dropna()\n",
    "filtered_train_data = filtered_train_data.drop(\"date\", axis=1)\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "#filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "filtered_train_data['t5'] = filtered_train_data['sqft_living15']**2 / np.sqrt(filtered_train_data['sqft_lot15'])\n",
    "filtered_train_data = filtered_train_data.drop(\"sqft_living15\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "corr_matrix = housing_train.corr()\n",
    "corr_matrix[\"price\"].sort_values(ascending=False)\n",
    "\n",
    "filtered_train_data = filtered_train_data.drop('waterfront',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('yr_renovated',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('years_since_renovation',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('Totalviews',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_day_name',axis=1)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = -1, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm.fit(sh_t_data, sh_t_target)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=4)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c638c",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# os.chdir('C:/Users/kksp1/OneDrive/Desktop/3_2학기 해야할 일/수업/3-2/머신러닝/미니프로젝트/풀젝_3')\n",
    "#print(os.getcwd())\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# # 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'] )\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "# housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "# housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1/(housing_train[\"sqft_living\"]+housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living']*housing_train['grade'])/2\n",
    "\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.dropna()\n",
    "filtered_train_data = filtered_train_data.drop(\"date\", axis=1)\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "#filtered_train_data = filtered_train_data.drop('waterfront',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('yr_renovated',axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('years_since_renovation',axis=1)\n",
    "# filtered_train_data = filtered_train_data.drop('tr_day_name',axis=1)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = -1, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8bfeff",
   "metadata": {},
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "import pandas as np\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# # 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 5. 우편번호 관련 특성\n",
    "# (이 예시에서는 단순히 우편번호를 이용하여 평균 가격을 나타냄) ##### 삭제해야할 가능성있음\n",
    "zipcode_prices = housing_train.groupby('zipcode')['price'].mean().to_dict()\n",
    "housing_train['average_price_by_zipcode'] = housing_train['zipcode'].map(zipcode_prices)\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toal_sizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15'] + housing_train['sqft_lot']\n",
    "\n",
    "housing_train['views+basement'] = housing_train['view'] + housing_train['sqft_basement']\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "# housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "# housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "# housing_train[\"tr_day\"] = housing_train[\"date\"].dt.day\n",
    "\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m-%d')\n",
    "# housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "# housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "# housing_train[\"tr_day\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "housing_target = housing_train['price']\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "housing_train = housing_train.drop('price', axis=1)\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(housing_train))\n",
    "sh_t_data = housing_train.values[sh_in]\n",
    "sh_t_target = housing_target.values[sh_in]\n",
    "\n",
    "# LightGBM 모델 정의\n",
    "lgbm = LGBMRegressor(random_state=0)\n",
    "\n",
    "# Extra Trees 모델 정의\n",
    "extratree = ExtraTreesRegressor(random_state=0)\n",
    "\n",
    "# 그리드 서치 파라미터 설정\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "param_grid_extratree = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "# LightGBM 그리드 서치\n",
    "grid_search_lgbm = GridSearchCV(lgbm, param_grid_lgbm, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1, verbose=2)\n",
    "grid_search_lgbm.fit(sh_t_data, sh_t_target)\n",
    "\n",
    "# Extra Trees 그리드 서치\n",
    "grid_search_extratree = GridSearchCV(extratree, param_grid_extratree, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1, verbose=2)\n",
    "grid_search_extratree.fit(sh_t_data, sh_t_target)\n",
    "\n",
    "# 최적의 파라미터 출력\n",
    "print(\"Best parameters for LightGBM:\", grid_search_lgbm.best_params_)\n",
    "print(\"Best parameters for Extra Trees:\", grid_search_extratree.best_params_)\n",
    "\n",
    "# 최적의 파라미터를 사용하여 모델 재설정\n",
    "best_lgbm = grid_search_lgbm.best_estimator_\n",
    "best_extratree = grid_search_extratree.best_estimator_\n",
    "\n",
    "# 보팅 리그레서 정의\n",
    "voting_reg = VotingRegressor(estimators=[('lgbm', best_lgbm), ('extratree', best_extratree)])\n",
    "\n",
    "# 보팅 리그레서 평가\n",
    "voting_scores = cross_val_score(voting_reg, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=5, n_jobs=-1)\n",
    "voting_rmse_scores = np.sqrt(-voting_scores)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(voting_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12101273",
   "metadata": {},
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "import pandas as np\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# # 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 5. 우편번호 관련 특성\n",
    "# (이 예시에서는 단순히 우편번호를 이용하여 평균 가격을 나타냄) ##### 삭제해야할 가능성있음\n",
    "zipcode_prices = housing_train.groupby('zipcode')['price'].mean().to_dict()\n",
    "housing_train['average_price_by_zipcode'] = housing_train['zipcode'].map(zipcode_prices)\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toal_sizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15'] + housing_train['sqft_lot']\n",
    "\n",
    "housing_train['views+basement'] = housing_train['view'] + housing_train['sqft_basement']\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "# housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "# housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "# housing_train[\"tr_day\"] = housing_train[\"date\"].dt.day\n",
    "\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m-%d')\n",
    "# housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "# housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "# housing_train[\"tr_day\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "housing_target = housing_train['price']\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "housing_train = housing_train.drop('price', axis=1)\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(housing_train))\n",
    "sh_t_data = housing_train.values[sh_in]\n",
    "sh_t_target = housing_target.values[sh_in]\n",
    "\n",
    "# XGBoost 모델 import\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# XGBoost 모델 정의\n",
    "xgb = XGBRegressor(\n",
    "    max_depth=6,  # max_depth 설정\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    min_child_weight=1,  # min_child_weight 설정\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=1.0,\n",
    "    gamma=0.0,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=1.0,\n",
    "    objective='reg:squarederror',  # regression용 목적 함수\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "xgb_scores = cross_val_score(xgb, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab5b9db",
   "metadata": {},
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "import pandas as np\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# # 1. 연도 관련 특성\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "# 2. 면적 관련 특성\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "# 3. 위치 관련 특성\n",
    "# (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# 4. 각종 비율 관련 특성\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "# 5. 우편번호 관련 특성\n",
    "# (이 예시에서는 단순히 우편번호를 이용하여 평균 가격을 나타냄) ##### 삭제해야할 가능성있음\n",
    "zipcode_prices = housing_train.groupby('zipcode')['price'].mean().to_dict()\n",
    "housing_train['average_price_by_zipcode'] = housing_train['zipcode'].map(zipcode_prices)\n",
    "\n",
    "# 전망 관련 특성 합\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toal_sizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15'] + housing_train['sqft_lot']\n",
    "\n",
    "housing_train['views+basement'] = housing_train['view'] + housing_train['sqft_basement']\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "# housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "# housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "# housing_train[\"tr_day\"] = housing_train[\"date\"].dt.day\n",
    "\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m-%d')\n",
    "# housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "# housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "# housing_train[\"tr_day\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "housing_target = housing_train['price']\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "housing_train = housing_train.drop('price', axis=1)\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(housing_train))\n",
    "sh_t_data = housing_train.values[sh_in]\n",
    "sh_t_target = housing_target.values[sh_in]\n",
    "\n",
    "# XGBoost 모델 import\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# XGBoost 모델 정의\n",
    "xgb = XGBRegressor(random_state=0)\n",
    "\n",
    "# 그리드 서치 파라미터 설정\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],  # max_depth 설정\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'min_child_weight': [1, 3, 5],  # min_child_weight 설정\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0.0, 0.1, 0.2],\n",
    "    'reg_alpha': [0.0, 0.1, 0.2],\n",
    "    'reg_lambda': [0.8, 1.0, 1.2]\n",
    "}\n",
    "\n",
    "# XGBoost 그리드 서치\n",
    "grid_search_xgb = GridSearchCV(xgb, param_grid, scoring=\"neg_mean_squared_error\", cv=5, n_jobs=-1)\n",
    "grid_search_xgb.fit(sh_t_data, sh_t_target)\n",
    "\n",
    "# 최적의 파라미터 출력\n",
    "print(\"Best parameters for XGBoost:\", grid_search_xgb.best_params_)\n",
    "\n",
    "# 최적의 파라미터를 사용하여 모델 재설정\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "\n",
    "# XGBoost 모델 평가\n",
    "xgb_scores = cross_val_score(best_xgb, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01181c89",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 제거\n",
    "for column in housing_train.columns:\n",
    "    # 이상치 제거\n",
    "    mean_value = housing_train[column].mean()\n",
    "    std_value = housing_train[column].std()\n",
    "    outlier_threshold = 3  # 이상치 판단을 위한 임계값\n",
    "    housing_train = housing_train[~((housing_train[column] - mean_value).abs() > outlier_threshold * std_value)]\n",
    "\n",
    "def remove_outliers(df):\n",
    "    variables = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "    for variable in variables:\n",
    "        df = df[np.abs(df[variable] - df[variable].mean()) <= (3 * df[variable].std())]\n",
    "    return df\n",
    "\n",
    "housing_train = remove_outliers(housing_train)\n",
    "\n",
    "# 여기까지 수정된 부분\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "xgb = XGBRegressor(objective ='reg:squarederror', random_state=0)\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 최적의 모델\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "print(f\"best_xgb_model : {best_xgb_model}\")\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(best_xgb_model, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c81415",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "housing_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f953c7b",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 대체\n",
    "for column in housing_train.columns:\n",
    "    # 이상치 판단\n",
    "    mean_value = housing_train[column].mean()\n",
    "    std_value = housing_train[column].std()\n",
    "    outlier_threshold = 4  # 이상치 판단을 위한 임계값\n",
    "    \n",
    "    # 이상치를 특성의 중간값으로 대체\n",
    "    housing_train[column] = np.where(\n",
    "        (housing_train[column] - mean_value).abs() > outlier_threshold * std_value,\n",
    "        housing_train[column].median(),\n",
    "        housing_train[column]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "filtered_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90418133",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 대체\n",
    "for column in housing_train.columns:\n",
    "    # 이상치 판단\n",
    "    mean_value = housing_train[column].mean()\n",
    "    std_value = housing_train[column].std()\n",
    "    outlier_threshold = 4  # 이상치 판단을 위한 임계값\n",
    "    \n",
    "    # 이상치를 특성의 중간값으로 대체\n",
    "    housing_train[column] = np.where(\n",
    "        (housing_train[column] - mean_value).abs() > outlier_threshold * std_value,\n",
    "        housing_train[column].median(),\n",
    "        housing_train[column]\n",
    "    )\n",
    "\n",
    "# 여기서 remove_outliers 함수가 호출되기 전에 이미 이상치가 처리되었으므로 주석 처리\n",
    "# def replace_outliers_with_median(df):\n",
    "#     variables = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "#     for variable in variables:\n",
    "#         mean_value = df[variable].mean()\n",
    "#         std_value = df[variable].std()\n",
    "#         outlier_threshold = 3  # 이상치 판단을 위한 임계값\n",
    "        \n",
    "#         # 이상치를 특성의 중간값으로 대체\n",
    "#         df[variable] = np.where(\n",
    "#             (df[variable] - mean_value).abs() > outlier_threshold * std_value,\n",
    "#             df[variable].median(),\n",
    "#             df[variable]\n",
    "#         )\n",
    "#     return df\n",
    "# housing_train = remove_outliers(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "filtered_train_data\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "xgb = XGBRegressor(objective ='reg:squarederror', random_state=0)\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 최적의 모델\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "print(f\"best_xgb_model : {best_xgb_model}\")\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(best_xgb_model, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f95aa2",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "for i in range(2, 10):\n",
    "    print(\"===========================================================================================================\")\n",
    "    print(f\"{i}번째 반복. 즉, i: {i}\")\n",
    "    # 이상치 대체\n",
    "    for column in housing_train.columns:\n",
    "        # 이상치 판단\n",
    "        mean_value = housing_train[column].mean()\n",
    "        std_value = housing_train[column].std()\n",
    "        outlier_threshold = i  # 이상치 판단을 위한 임계값\n",
    "\n",
    "        # 이상치를 특성의 중간값으로 대체\n",
    "        housing_train[column] = np.where(\n",
    "            (housing_train[column] - mean_value).abs() > outlier_threshold * std_value,\n",
    "            housing_train[column].median(),\n",
    "            housing_train[column]\n",
    "        )\n",
    "\n",
    "    # 여기서 remove_outliers 함수가 호출되기 전에 이미 이상치가 처리되었으므로 주석 처리\n",
    "    # def replace_outliers_with_median(df):\n",
    "    #     variables = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "    #     for variable in variables:\n",
    "    #         mean_value = df[variable].mean()\n",
    "    #         std_value = df[variable].std()\n",
    "    #         outlier_threshold = 3  # 이상치 판단을 위한 임계값\n",
    "\n",
    "    #         # 이상치를 특성의 중간값으로 대체\n",
    "    #         df[variable] = np.where(\n",
    "    #             (df[variable] - mean_value).abs() > outlier_threshold * std_value,\n",
    "    #             df[variable].median(),\n",
    "    #             df[variable]\n",
    "    #         )\n",
    "    #     return df\n",
    "    # housing_train = remove_outliers(housing_train)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(housing_train)\n",
    "    X = imputer.transform(housing_train)\n",
    "    housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "    # 스케일링\n",
    "    filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "    # 목표 변수\n",
    "    train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "    print(f\"filtered_train_data.shpae: {filtered_train_data.shape}\")\n",
    "\n",
    "    # XGBoost 모델 초기화\n",
    "    xgb = XGBRegressor(objective ='reg:squarederror', random_state=0)\n",
    "\n",
    "    # 그리드 서치를 위한 하이퍼파라미터 그리드 정의\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    }\n",
    "\n",
    "    # GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "    grid_search = GridSearchCV(xgb, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(filtered_train_data, train_target)\n",
    "\n",
    "    # 최적의 모델\n",
    "    best_xgb_model = grid_search.best_estimator_\n",
    "    print(f\"best_xgb_model : {best_xgb_model}\")\n",
    "\n",
    "    # Cross-validation 결과 출력\n",
    "    xgb_scores = cross_val_score(best_xgb_model, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "    xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=======================================================================================\")\n",
    "    # Cross-validation 결과 출력\n",
    "    display_scores(xgb_rmse_scores)\n",
    "    print(\"=======================================================================================\")\n",
    "    print(\"===========================================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ad5c1",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "for i in range(2, 10):\n",
    "    print(\"===========================================================================================================\")\n",
    "    print(f\"{i}번째 반복. 즉, i: {i}\")\n",
    "    # 이상치 대체\n",
    "    for column in housing_train.columns:\n",
    "        # 이상치 판단\n",
    "        mean_value = housing_train[column].mean()\n",
    "        std_value = housing_train[column].std()\n",
    "        outlier_threshold = i  # 이상치 판단을 위한 임계값\n",
    "\n",
    "        # 이상치를 특성의 중간값으로 대체\n",
    "        housing_train[column] = np.where(\n",
    "            (housing_train[column] - mean_value).abs() > outlier_threshold * std_value,\n",
    "            housing_train[column].median(),\n",
    "            housing_train[column]\n",
    "        )\n",
    "\n",
    "    # 여기서 remove_outliers 함수가 호출되기 전에 이미 이상치가 처리되었으므로 주석 처리\n",
    "    # def replace_outliers_with_median(df):\n",
    "    #     variables = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "    #     for variable in variables:\n",
    "    #         mean_value = df[variable].mean()\n",
    "    #         std_value = df[variable].std()\n",
    "    #         outlier_threshold = 3  # 이상치 판단을 위한 임계값\n",
    "\n",
    "    #         # 이상치를 특성의 중간값으로 대체\n",
    "    #         df[variable] = np.where(\n",
    "    #             (df[variable] - mean_value).abs() > outlier_threshold * std_value,\n",
    "    #             df[variable].median(),\n",
    "    #             df[variable]\n",
    "    #         )\n",
    "    #     return df\n",
    "    # housing_train = remove_outliers(housing_train)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(housing_train)\n",
    "    X = imputer.transform(housing_train)\n",
    "    housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "    # 스케일링\n",
    "    filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "    # 목표 변수\n",
    "    train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "    print(f\"filtered_train_data.shpae: {filtered_train_data.shape}\")\n",
    "\n",
    "    # XGBoost 모델 초기화\n",
    "    xgb = XGBRegressor(objective ='reg:squarederror', random_state=0)\n",
    "\n",
    "    # 그리드 서치를 위한 하이퍼파라미터 그리드 정의\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200, 300, 500],\n",
    "        'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7],\n",
    "        'max_depth': [None, 3, 4, 5, 10, 30, 50]\n",
    "    }\n",
    "\n",
    "    # GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "    grid_search = GridSearchCV(xgb, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(filtered_train_data, train_target)\n",
    "\n",
    "    # 최적의 모델\n",
    "    best_xgb_model = grid_search.best_estimator_\n",
    "    print(f\"best_xgb_model : {best_xgb_model}\")\n",
    "\n",
    "    # Cross-validation 결과 출력\n",
    "    xgb_scores = cross_val_score(best_xgb_model, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "    xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=======================================================================================\")\n",
    "    # Cross-validation 결과 출력\n",
    "    display_scores(xgb_rmse_scores)\n",
    "    print(\"=======================================================================================\")\n",
    "    print(\"===========================================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501c663",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "for i in np.arange(1, 15, 2):\n",
    "\n",
    "    def display_scores(scores):\n",
    "        print(\"Scores:\", scores)\n",
    "        print(\"Mean:\", scores.mean())\n",
    "        print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "    def handle_outliers_zscore(data):\n",
    "        # 각 특성에 대한 z-스코어 계산\n",
    "        z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "        # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "        for column in z_scores.columns:\n",
    "#             print(z_scores[column])\n",
    "            outliers = z_scores[column] > i\n",
    "            median_value = data[column].median()\n",
    "            data.loc[outliers, column] = median_value\n",
    "\n",
    "        return data\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    input_file = \"kc_house_data.csv\"\n",
    "    housing_train = pd.read_csv(input_file)\n",
    "    \n",
    "    # 목표 변수\n",
    "    train_target = housing_train[\"price\"].copy()\n",
    "    \n",
    "    # 불필요한 열 제거\n",
    "    housing_train = housing_train.drop([\"id\", 'price'], axis=1)\n",
    "\n",
    "    # 특성 공학\n",
    "    housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "    housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "    housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "    housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "    housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "    housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "    housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "    housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "    housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "    housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "    housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "    housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "    housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "    housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "    housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "    housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "    housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "    housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "    housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "    housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # 이상치 처리\n",
    "    housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(housing_train)\n",
    "    X = imputer.transform(housing_train)\n",
    "    housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "    # 스케일링\n",
    "    filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name'], axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "    # XGBoost 모델 초기화 (과적합을 유도하기 위한 파라미터 설정)\n",
    "    xgb_overfit = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=0,\n",
    "        n_estimators=1000,          # 트리의 개수 (나무의 수)\n",
    "        learning_rate=0.01,         # 학습률 (나무의 기여 정도를 조절)\n",
    "        max_depth=10,               # 트리의 최대 깊이\n",
    "        min_child_weight=1,         # 리프 노드에 필요한 최소 샘플 수\n",
    "        gamma=0.0,                  # 나무의 가지치기를 위한 최소 손실 감소 값\n",
    "        subsample=0.8,              # 각 트리에 사용될 훈련 데이터의 일부 (1.0은 전체 데이터 사용)\n",
    "        colsample_bytree=0.8        # 각 트리에 사용될 특성의 일부 (1.0은 전체 특성 사용)\n",
    "    )\n",
    "    \n",
    "    # Cross-validation 결과 출력\n",
    "    xgb_overfit_scores = cross_val_score(xgb_overfit, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "    xgb_overfit_rmse_scores = np.sqrt(-xgb_overfit_scores)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=======================================================================================\")\n",
    "    print(f\"임계값: {i}\")\n",
    "    # Cross-validation 결과 출력\n",
    "    display_scores(xgb_overfit_rmse_scores)\n",
    "    print(\"=======================================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ff647",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in np.arange(3, 15, 2):\n",
    "\n",
    "    def display_scores(scores):\n",
    "        print(\"Scores:\", scores)\n",
    "        print(\"Mean:\", scores.mean())\n",
    "        print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "    def handle_outliers_zscore(data):\n",
    "        # 각 특성에 대한 z-스코어 계산\n",
    "        z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "        # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "        for column in z_scores.columns:\n",
    "#             print(z_scores[column])\n",
    "            outliers = z_scores[column] > i\n",
    "            median_value = data[column].median()\n",
    "            data.loc[outliers, column] = median_value\n",
    "\n",
    "        return data\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    input_file = \"kc_house_data.csv\"\n",
    "    housing_train = pd.read_csv(input_file)\n",
    "    \n",
    "    # 목표 변수\n",
    "    train_target = housing_train[\"price\"].copy()\n",
    "    \n",
    "    # 불필요한 열 제거\n",
    "    housing_train = housing_train.drop([\"id\", 'price'], axis=1)\n",
    "\n",
    "    # 특성 공학\n",
    "    housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "    housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "    housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "    housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "    housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "    housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "    housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "    housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "    housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "    housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "    housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "    housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "    housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "    housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "    housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "    housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "    housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "    housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "    housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "    housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # 이상치 처리\n",
    "    housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(housing_train)\n",
    "    X = imputer.transform(housing_train)\n",
    "    housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "    # 스케일링\n",
    "    filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name'], axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "    # 특성들의 z-score 계산\n",
    "    z_scores = np.abs((filtered_train_data - filtered_train_data.mean()) / filtered_train_data.std())\n",
    "\n",
    "    # 특성들의 z-score를 시각화\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    z_scores.boxplot(vert=False)\n",
    "    plt.title(f\"Z-Scores for Threshold {i}\")\n",
    "    plt.show()\n",
    "        \n",
    "    # XGBoost 모델 초기화 (과적합을 유도하기 위한 파라미터 설정)\n",
    "    xgb_overfit = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=0,\n",
    "        n_estimators=1000,          # 트리의 개수 (나무의 수)\n",
    "        learning_rate=0.01,         # 학습률 (나무의 기여 정도를 조절)\n",
    "        max_depth=10,               # 트리의 최대 깊이\n",
    "        min_child_weight=1,         # 리프 노드에 필요한 최소 샘플 수\n",
    "        gamma=0.0,                  # 나무의 가지치기를 위한 최소 손실 감소 값\n",
    "        subsample=0.8,              # 각 트리에 사용될 훈련 데이터의 일부 (1.0은 전체 데이터 사용)\n",
    "        colsample_bytree=0.8        # 각 트리에 사용될 특성의 일부 (1.0은 전체 특성 사용)\n",
    "    )\n",
    "    \n",
    "    # Cross-validation 결과 출력\n",
    "    xgb_overfit_scores = cross_val_score(xgb_overfit, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "    xgb_overfit_rmse_scores = np.sqrt(-xgb_overfit_scores)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=======================================================================================\")\n",
    "    print(f\"임계값: {i}\")\n",
    "    # Cross-validation 결과 출력\n",
    "    display_scores(xgb_overfit_rmse_scores)\n",
    "    print(\"=======================================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913fb22",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in np.arange(1, 15, 1):\n",
    "\n",
    "    def display_scores(scores):\n",
    "        print(\"Scores:\", scores)\n",
    "        print(\"Mean:\", scores.mean())\n",
    "        print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "    def handle_outliers_zscore(data):\n",
    "        # 각 특성에 대한 z-스코어 계산\n",
    "        z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "        # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "        for column in z_scores.columns:\n",
    "#             print(z_scores[column])\n",
    "            outliers = z_scores[column] > i\n",
    "            median_value = data[column].median()\n",
    "            data.loc[outliers, column] = median_value\n",
    "\n",
    "        return data\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    input_file = \"kc_house_data.csv\"\n",
    "    housing_train = pd.read_csv(input_file)\n",
    "    \n",
    "    # 목표 변수\n",
    "    train_target = housing_train[\"price\"].copy()\n",
    "    \n",
    "    # 불필요한 열 제거\n",
    "    housing_train = housing_train.drop([\"id\", 'price'], axis=1)\n",
    "\n",
    "    # 1. 연도 관련 특성\n",
    "    housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "    housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "\n",
    "    # 2. 면적 관련 특성\n",
    "    housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "    housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "\n",
    "    # 3. 위치 관련 특성\n",
    "    # (이 예시에서는 단순히 위도와 경도의 조합으로 나타냄)\n",
    "    housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "    # 4. 각종 비율 관련 특성\n",
    "    housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "    housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "    # 전만 관련 특성 합\n",
    "    housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "    housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "\n",
    "    housing_train['date'] = pd.to_datetime(housing_train['date'] )\n",
    "    housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "    housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "    housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "    housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "    housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "    housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "    # \n",
    "    housing_train[\"house_per_bathrooms\"] = 1/housing_train[\"bathrooms\"]\n",
    "    housing_train[\"house_per_bedrooms\"] = 1/housing_train[\"bedrooms\"]\n",
    "    housing_train[\"house_per_sqft_livings\"] = 1/(housing_train[\"sqft_living\"]+housing_train[\"sqft_living15\"])\n",
    "\n",
    "    #\n",
    "    housing_train[\"house_per_bathrooms_sq\"] = (1/housing_train[\"bathrooms\"])**2\n",
    "\n",
    "    housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # 이상치 처리\n",
    "    housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(housing_train)\n",
    "    X = imputer.transform(housing_train)\n",
    "    housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "    # 스케일링\n",
    "    filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews'], axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "        \n",
    "    # XGBoost 모델 초기화 (과적합을 유도하기 위한 파라미터 설정)\n",
    "    xgb_overfit = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=0,\n",
    "        n_estimators=1000,          # 트리의 개수 (나무의 수)\n",
    "        learning_rate=0.01,         # 학습률 (나무의 기여 정도를 조절)\n",
    "        max_depth=10,               # 트리의 최대 깊이\n",
    "        min_child_weight=1,         # 리프 노드에 필요한 최소 샘플 수\n",
    "        gamma=0.0,                  # 나무의 가지치기를 위한 최소 손실 감소 값\n",
    "        subsample=0.8,              # 각 트리에 사용될 훈련 데이터의 일부 (1.0은 전체 데이터 사용)\n",
    "        colsample_bytree=0.8        # 각 트리에 사용될 특성의 일부 (1.0은 전체 특성 사용)\n",
    "    )\n",
    "    \n",
    "    # Cross-validation 결과 출력\n",
    "    xgb_overfit_scores = cross_val_score(xgb_overfit, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "    xgb_overfit_rmse_scores = np.sqrt(-xgb_overfit_scores)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=======================================================================================\")\n",
    "    print(f\"임계값: {i}\")\n",
    "    # Cross-validation 결과 출력\n",
    "    display_scores(xgb_overfit_rmse_scores)\n",
    "    print(\"=======================================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e894e73",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in np.arange(3, 15, 2):\n",
    "\n",
    "    def display_scores(scores):\n",
    "        print(\"Scores:\", scores)\n",
    "        print(\"Mean:\", scores.mean())\n",
    "        print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "    def handle_outliers_zscore(data):\n",
    "        # 각 특성에 대한 z-스코어 계산\n",
    "        z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "        # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "        for column in z_scores.columns:\n",
    "#             print(z_scores[column])\n",
    "            outliers = z_scores[column] > i\n",
    "            median_value = data[column].median()\n",
    "            data.loc[outliers, column] = median_value\n",
    "\n",
    "        return data\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    input_file = \"kc_house_data.csv\"\n",
    "    housing_train = pd.read_csv(input_file)\n",
    "    \n",
    "    # 목표 변수\n",
    "    train_target = housing_train[\"price\"].copy()\n",
    "    \n",
    "    # 불필요한 열 제거\n",
    "    housing_train = housing_train.drop([\"id\", 'price'], axis=1)\n",
    "\n",
    "    # 특성 공학\n",
    "    housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "    housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "    housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "    housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "    housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "    housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "    housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "    housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "    housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "    housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "    housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "    housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "    housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "    housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "    housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "    housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "    housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "    housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "    housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "    housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # 이상치 처리\n",
    "    housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(housing_train)\n",
    "    X = imputer.transform(housing_train)\n",
    "    housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "    # 스케일링\n",
    "    filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name'], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    filtered_train_data = scaler.fit_transform(filtered_train_data)\n",
    "        \n",
    "    # XGBoost 모델 초기화 (과적합을 유도하기 위한 파라미터 설정)\n",
    "    xgb_overfit = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=0,\n",
    "        n_estimators=1000,          # 트리의 개수 (나무의 수)\n",
    "        learning_rate=0.01,         # 학습률 (나무의 기여 정도를 조절)\n",
    "        max_depth=10,               # 트리의 최대 깊이\n",
    "        min_child_weight=1,         # 리프 노드에 필요한 최소 샘플 수\n",
    "        gamma=0.0,                  # 나무의 가지치기를 위한 최소 손실 감소 값\n",
    "        subsample=0.8,              # 각 트리에 사용될 훈련 데이터의 일부 (1.0은 전체 데이터 사용)\n",
    "        colsample_bytree=0.8        # 각 트리에 사용될 특성의 일부 (1.0은 전체 특성 사용)\n",
    "    )\n",
    "    \n",
    "    # Cross-validation 결과 출력\n",
    "    xgb_overfit_scores = cross_val_score(xgb_overfit, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "    xgb_overfit_rmse_scores = np.sqrt(-xgb_overfit_scores)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=======================================================================================\")\n",
    "    print(f\"임계값: {i}\")\n",
    "    # Cross-validation 결과 출력\n",
    "    display_scores(xgb_overfit_rmse_scores)\n",
    "    print(\"=======================================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9014416",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in np.arange(3, 20, 2):\n",
    "\n",
    "    def display_scores(scores):\n",
    "        print(\"Scores:\", scores)\n",
    "        print(\"Mean:\", scores.mean())\n",
    "        print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "    def handle_outliers_zscore(data):\n",
    "        # 각 특성에 대한 z-스코어 계산\n",
    "        z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "        # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "        for column in z_scores.columns:\n",
    "    #             print(z_scores[column])\n",
    "            outliers = z_scores[column] > i\n",
    "            median_value = data[column].median()\n",
    "            data.loc[outliers, column] = median_value\n",
    "\n",
    "        return data\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    input_file = \"kc_house_data.csv\"\n",
    "    housing_train = pd.read_csv(input_file)\n",
    "\n",
    "    # 목표 변수\n",
    "    train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "    # 불필요한 열 제거\n",
    "    housing_train = housing_train.drop([\"id\", 'price'], axis=1)\n",
    "\n",
    "    # 특성 공학\n",
    "    housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "    housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "    housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "    housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "    housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "    housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "    housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "    housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "    housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "    housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "    housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "    housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "    housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "    housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "    housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "    housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "    housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "    housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "    housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "    housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # 이상치 처리\n",
    "    housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(housing_train)\n",
    "    X = imputer.transform(housing_train)\n",
    "    housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "    # 스케일링\n",
    "    filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name'], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)  # DataFrame으로 다시 변환\n",
    "\n",
    "    # XGBoost 모델 초기화 (과적합을 유도하기 위한 파라미터 설정)\n",
    "    xgb_overfit = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=0,\n",
    "        n_estimators=1000,          # 트리의 개수 (나무의 수)\n",
    "        learning_rate=0.01,         # 학습률 (나무의 기여 정도를 조절)\n",
    "        max_depth=10,               # 트리의 최대 깊이\n",
    "        min_child_weight=1,         # 리프 노드에 필요한 최소 샘플 수\n",
    "        gamma=0.0,                  # 나무의 가지치기를 위한 최소 손실 감소 값\n",
    "        subsample=0.8,              # 각 트리에 사용될 훈련 데이터의 일부 (1.0은 전체 데이터 사용)\n",
    "        colsample_bytree=0.8        # 각 트리에 사용될 특성의 일부 (1.0은 전체 특성 사용)\n",
    "    )\n",
    "\n",
    "    # 모델 훈련\n",
    "    xgb_overfit.fit(filtered_train_data, train_target)\n",
    "\n",
    "    # 특성 중요도 얻기\n",
    "    feature_importances = xgb_overfit.feature_importances_\n",
    "\n",
    "    # 중요도를 기준으로 특성의 순위를 매김\n",
    "    feature_importance_ranking = pd.Series(feature_importances, index=filtered_train_data.columns).sort_values(ascending=False)\n",
    "\n",
    "    # 특성 중요도 시각화\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    feature_importance_ranking.plot(kind='barh')\n",
    "    plt.title(\"Feature Importance Ranking\")\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "\n",
    "    # Cross-validation 결과 출력\n",
    "    xgb_overfit_scores = cross_val_score(xgb_overfit, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "    xgb_overfit_rmse_scores = np.sqrt(-xgb_overfit_scores)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=======================================================================================\")\n",
    "    print(f\"임계값: {i}\")\n",
    "    # Cross-validation 결과 출력\n",
    "    display_scores(xgb_overfit_rmse_scores)\n",
    "    print(\"=======================================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef4cff",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "#             print(z_scores[column])\n",
    "        outliers = z_scores[column] > 7\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop([\"id\", 'price'], axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', \n",
    "                                          'date', 'bedrooms', 'tr_year', 'bathrooms', 'floors', 'tr_month', 'sqft_lot', 'sqft_basement',\n",
    "                                         'condition', 'indoor_to_outdoor_ratio', 'sqft_above', 'sqft_lot15', 'basement_to_living_ratio',\n",
    "                                         'bedrooms_to_bathrooms_ratio', 'living_to_floors_ratio', 'sqft_living', 'sqft_living15', 'house_age',\n",
    "                                         'yr_built', 'zipcode'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)  # DataFrame으로 다시 변환\n",
    "\n",
    "# XGBoost 모델 초기화 (과적합을 유도하기 위한 파라미터 설정)\n",
    "xgb_overfit = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=1000,          # 트리의 개수 (나무의 수)\n",
    "    learning_rate=0.01,         # 학습률 (나무의 기여 정도를 조절)\n",
    "    max_depth=10,               # 트리의 최대 깊이\n",
    "    min_child_weight=1,         # 리프 노드에 필요한 최소 샘플 수\n",
    "    gamma=0.0,                  # 나무의 가지치기를 위한 최소 손실 감소 값\n",
    "    subsample=0.8,              # 각 트리에 사용될 훈련 데이터의 일부 (1.0은 전체 데이터 사용)\n",
    "    colsample_bytree=0.8        # 각 트리에 사용될 특성의 일부 (1.0은 전체 특성 사용)\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "xgb_overfit.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 특성 중요도 얻기\n",
    "feature_importances = xgb_overfit.feature_importances_\n",
    "\n",
    "# 중요도를 기준으로 특성의 순위를 매김\n",
    "feature_importance_ranking = pd.Series(feature_importances, index=filtered_train_data.columns).sort_values(ascending=False)\n",
    "\n",
    "# 특성 중요도 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_importance_ranking.plot(kind='barh')\n",
    "plt.title(\"Feature Importance Ranking\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_overfit_scores = cross_val_score(xgb_overfit, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "xgb_overfit_rmse_scores = np.sqrt(-xgb_overfit_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"임계값: 7\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_overfit_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172f76a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "#             print(z_scores[column])\n",
    "        outliers = z_scores[column] > 7\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop([\"id\", 'price'], axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)  # DataFrame으로 다시 변환\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "xgb_custom_params = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=500,           # 트리의 개수 (나무의 수)\n",
    "    learning_rate=0.1,          # 학습률 (나무의 기여 정도를 조절)\n",
    "    max_depth=None,             # 트리의 최대 깊이\n",
    "    min_child_weight=10,        # 리프 노드에 필요한 최소 샘플 수\n",
    "    gamma=0,                    # 나무의 가지치기를 위한 최소 손실 감소 값\n",
    "    subsample=0.8,              # 각 트리에 사용될 훈련 데이터의 일부 (1.0은 전체 데이터 사용)\n",
    "    colsample_bytree=0.5        # 각 트리에 사용될 특성의 일부 (1.0은 전체 특성 사용)\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "xgb_custom_params.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 특성 중요도 얻기\n",
    "feature_importances_custom = xgb_custom_params.feature_importances_\n",
    "\n",
    "# 중요도를 기준으로 특성의 순위를 매김\n",
    "feature_importance_ranking_custom = pd.Series(feature_importances_custom, index=filtered_train_data.columns).sort_values(ascending=False)\n",
    "\n",
    "# 특성 중요도 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_importance_ranking_custom.plot(kind='barh')\n",
    "plt.title(\"Custom XGBoost Feature Importance Ranking\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_overfit_scores = cross_val_score(xgb_overfit, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "xgb_overfit_rmse_scores = np.sqrt(-xgb_overfit_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"임계값: 7\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_overfit_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1941f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "#             print(z_scores[column])\n",
    "        outliers = z_scores[column] > 7\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop([\"id\", 'price'], axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)  # DataFrame으로 다시 변환\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "xgb_custom_params = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=500,           # 트리의 개수 (나무의 수)\n",
    "    learning_rate=0.1,          # 학습률 (나무의 기여 정도를 조절)\n",
    "    max_depth=None,             # 트리의 최대 깊이\n",
    "    min_child_weight=10,        # 리프 노드에 필요한 최소 샘플 수\n",
    "    gamma=0,                    # 나무의 가지치기를 위한 최소 손실 감소 값\n",
    "    subsample=0.8,              # 각 트리에 사용될 훈련 데이터의 일부 (1.0은 전체 데이터 사용)\n",
    "    colsample_bytree=0.5        # 각 트리에 사용될 특성의 일부 (1.0은 전체 특성 사용)\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "xgb_custom_params.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 특성 중요도 얻기\n",
    "feature_importances_custom = xgb_custom_params.feature_importances_\n",
    "\n",
    "# 중요도를 기준으로 특성의 순위를 매김\n",
    "feature_importance_ranking_custom = pd.Series(feature_importances_custom, index=filtered_train_data.columns).sort_values(ascending=False)\n",
    "\n",
    "# 특성 중요도 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_importance_ranking_custom.plot(kind='barh')\n",
    "plt.title(\"Custom XGBoost Feature Importance Ranking\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_overfit_scores = cross_val_score(xgb_overfit, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "xgb_overfit_rmse_scores = np.sqrt(-xgb_overfit_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"임계값: 7\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_overfit_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc403efc",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 3\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화 (주어진 파라미터 사용)\n",
    "xgb_custom_params = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=None,\n",
    "    min_child_weight=10,\n",
    "    gamma=0,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(xgb_custom_params, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe33533",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 7\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화 (주어진 파라미터 사용)\n",
    "xgb_custom_params = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=None,\n",
    "    min_child_weight=10,\n",
    "    gamma=0,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(xgb_custom_params, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20963648",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 1.5\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=0)\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 최적의 모델\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "print(f\"best_xgb_model : {best_xgb_model}\")\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(best_xgb_model, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259bf73b",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 1.5\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# XGBoost 모델 초기화 (주어진 파라미터 사용)\n",
    "xgb_custom_params = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=None,\n",
    "    min_child_weight=10,\n",
    "    gamma=0,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(xgb_custom_params, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce50934",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 1.5\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=0)\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [500],  # 과적합을 유도하기 위해 트리 수를 늘림\n",
    "    'learning_rate': [0.01],  # 낮은 학습률 사용\n",
    "    'max_depth': [5],  # 트리의 최대 깊이\n",
    "    'min_child_weight': [10],  # 리프 노드에 필요한 최소 샘플 수\n",
    "    'gamma': [0],  # 가지치기를 위한 최소 손실 감소 값\n",
    "    'colsample_bytree': [0.5]  # 특성 샘플링 비율\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 최적의 모델과 파라미터 출력\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(f\"Best XGB Model: {best_xgb_model}\")\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(best_xgb_model, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21197687",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 1.5\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=0)\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 600, 700],  # 과적합을 유도하기 위해 트리 수를 늘림\n",
    "    'learning_rate': [0.01, 0.05, 0.003, 0.005],  # 낮은 학습률 사용\n",
    "    'max_depth': [None, 5, 10],  # 트리의 최대 깊이\n",
    "    'min_child_weight': [5, 10, 20],  # 리프 노드에 필요한 최소 샘플 수\n",
    "    'gamma': [0],  # 가지치기를 위한 최소 손실 감소 값\n",
    "    'colsample_bytree': [0.5, 0.3, 0.7]  # 특성 샘플링 비율\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 최적의 모델과 파라미터 출력\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(f\"Best XGB Model: {best_xgb_model}\")\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(best_xgb_model, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0730e1",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 1.5\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화 (주어진 파라미터 사용)\n",
    "xgb_custom_params = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=None,\n",
    "    min_child_weight=10,\n",
    "    gamma=0,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "xgb_custom_params.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 특성 중요도 얻기\n",
    "feature_importances_custom = xgb_custom_params.feature_importances_\n",
    "\n",
    "# 중요도를 기준으로 특성의 순위를 매김\n",
    "feature_importance_ranking_custom = pd.Series(feature_importances_custom, index=filtered_train_data.columns).sort_values(ascending=False)\n",
    "\n",
    "# 특성 중요도 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_importance_ranking_custom.plot(kind='barh')\n",
    "plt.title(\"Custom XGBoost Feature Importance Ranking\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(xgb_custom_params, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542af788",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 1.5\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화 (주어진 파라미터 사용)\n",
    "xgb_custom_params = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=10,\n",
    "    min_child_weight=10,\n",
    "    gamma=0,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "xgb_custom_params.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 특성 중요도 얻기\n",
    "feature_importances_custom = xgb_custom_params.feature_importances_\n",
    "\n",
    "# 중요도를 기준으로 특성의 순위를 매김\n",
    "feature_importance_ranking_custom = pd.Series(feature_importances_custom, index=filtered_train_data.columns).sort_values(ascending=False)\n",
    "\n",
    "# 특성 중요도 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "feature_importance_ranking_custom.plot(kind='barh')\n",
    "plt.title(\"Custom XGBoost Feature Importance Ranking\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(xgb_custom_params, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a5a64d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 1.5\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "# print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화 (주어진 파라미터 사용)\n",
    "xgb_custom_params = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=10,\n",
    "    min_child_weight=10,\n",
    "    gamma=0,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "xgb_custom_params.fit(filtered_train_data, train_target)\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(xgb_custom_params, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dab3cf",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 1.5\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "# print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=0)\n",
    "\n",
    "# 그리드 서치를 위한 하이퍼파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [700, 800, 100, 1500],  # 과적합을 유도하기 위해 트리 수를 늘림\n",
    "    'learning_rate': [0.0001, 0.01, 0.003, 0.005],  # 낮은 학습률 사용\n",
    "    'max_depth': [None, 10, 30, 50, 100],  # 트리의 최대 깊이\n",
    "    'min_child_weight': [1, 5, 10, 20],  # 리프 노드에 필요한 최소 샘플 수\n",
    "    'gamma': [0],  # 가지치기를 위한 최소 손실 감소 값\n",
    "    'colsample_bytree': [0.5, 0.3, 0.7, 0.1]  # 특성 샘플링 비율\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(filtered_train_data, train_target)\n",
    "\n",
    "# 최적의 모델과 파라미터 출력\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(f\"Best XGB Model: {best_xgb_model}\")\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(best_xgb_model, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587bccd",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def handle_outliers_zscore(data):\n",
    "    # 각 특성에 대한 z-스코어 계산\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "    # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "    for column in z_scores.columns:\n",
    "        outliers = z_scores[column] > 1.5\n",
    "        median_value = data[column].median()\n",
    "        data.loc[outliers, column] = median_value\n",
    "\n",
    "    return data\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 이상치 처리\n",
    "housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 스케일링\n",
    "filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name', 'price'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "# 목표 변수\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "# print(f\"train_traget: {train_target}\")\n",
    "\n",
    "# XGBoost 모델 초기화 (주어진 파라미터 사용)\n",
    "xgb_custom_params = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=0,\n",
    "    n_estimators=900,\n",
    "    learning_rate=0.011,\n",
    "    max_depth=10,\n",
    "    min_child_weight=10,\n",
    "    gamma=0,\n",
    "    colsample_bytree=0.5\n",
    ")\n",
    "\n",
    "xgb_custom_params.fit(filtered_train_data, train_target)\n",
    "\n",
    "# Cross-validation 결과 출력\n",
    "xgb_scores = cross_val_score(xgb_custom_params, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"=======================================================================================\")\n",
    "print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "# Cross-validation 결과 출력\n",
    "display_scores(xgb_rmse_scores)\n",
    "print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa279c",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "for i in np.arange(2, 20, 1):\n",
    "    def display_scores(scores):\n",
    "        print(\"Scores:\", scores)\n",
    "        print(\"Mean:\", scores.mean())\n",
    "        print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "    def handle_outliers_zscore(data):\n",
    "        # 각 특성에 대한 z-스코어 계산\n",
    "        z_scores = np.abs((data - data.mean()) / data.std())\n",
    "\n",
    "        # 각 특성에 대해 z-스코어가 i보다 큰 값을 해당 특성의 중간값으로 대체\n",
    "        for column in z_scores.columns:\n",
    "            outliers = z_scores[column] > i\n",
    "            median_value = data[column].median()\n",
    "            data.loc[outliers, column] = median_value\n",
    "\n",
    "        return data\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    input_file = \"kc_house_data.csv\"\n",
    "    housing_train = pd.read_csv(input_file)\n",
    "\n",
    "    # 목표 변수\n",
    "    train_target = housing_train[\"price\"]\n",
    "#     print(f\"train_traget: {train_target}\")\n",
    "\n",
    "    # 불필요한 열 제거\n",
    "    housing_train = housing_train.drop([\"id\", \"price\"], axis=1)\n",
    "\n",
    "    # 특성 공학\n",
    "    housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "    housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "    housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "    housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "    housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "    housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "    housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "    housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "    housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "    housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "    housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "    housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "    housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "    housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "    housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "    housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "    housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "    housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "    housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "    housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # 이상치 처리\n",
    "    housing_train = handle_outliers_zscore(housing_train)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(housing_train)\n",
    "    X = imputer.transform(housing_train)\n",
    "    housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "    # 스케일링\n",
    "    filtered_train_data = housing_train.drop(['waterfront', 'yr_renovated', 'years_since_renovation', 'Totalviews', 'tr_day_name'], axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    filtered_train_data = pd.DataFrame(scaler.fit_transform(filtered_train_data), columns=filtered_train_data.columns)\n",
    "\n",
    "    # XGBoost 모델 초기화 (주어진 파라미터 사용)\n",
    "    xgb_custom_params = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=0,\n",
    "        n_estimators=700,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=10,\n",
    "        min_child_weight=10,\n",
    "        gamma=0,\n",
    "        colsample_bytree=0.5\n",
    "    )\n",
    "\n",
    "    xgb_custom_params.fit(filtered_train_data, train_target)\n",
    "\n",
    "    # 특성 중요도 얻기\n",
    "    feature_importances_custom = xgb_custom_params.feature_importances_\n",
    "\n",
    "    # 중요도를 기준으로 특성의 순위를 매김\n",
    "    feature_importance_ranking_custom = pd.Series(feature_importances_custom, index=filtered_train_data.columns).sort_values(ascending=False)\n",
    "\n",
    "    # 특성 중요도 시각화\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    feature_importance_ranking_custom.plot(kind='barh')\n",
    "    plt.title(\"Custom XGBoost Feature Importance Ranking\")\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()\n",
    "\n",
    "    # Cross-validation 결과 출력\n",
    "    xgb_scores = cross_val_score(xgb_custom_params, filtered_train_data, train_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4)\n",
    "    xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=======================================================================================\")\n",
    "    print(f\"filtered_train_data: {filtered_train_data.shape}\")\n",
    "    print(f\"train_target: {train_target}\")\n",
    "    print(f\"임계값 i: {i}\")\n",
    "    # Cross-validation 결과 출력\n",
    "    display_scores(xgb_rmse_scores)\n",
    "    print(\"=======================================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084632d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "train_target = housing_train[\"price\"]\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['1'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train = housing_train.drop(\"date\", axis=1)\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = None, min_data_in_leaf = 1, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 0.1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 1000,learning_rate = 0.1, \n",
    "                     num_leaves = 1000 ,random_state=0)\n",
    "\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5f36e",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "train_target = housing_train[\"price\"]\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['1'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train = housing_train.drop(\"date\", axis=1)\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = None, min_data_in_leaf = 1, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 0.1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 1000,learning_rate = 0.01, \n",
    "                     num_leaves = 1000 ,random_state=0)\n",
    "\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd903665",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "train_target = housing_train[\"price\"]\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['1'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train = housing_train.drop(\"date\", axis=1)\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "# LGBMRegressor 파라미터\n",
    "lgbm = LGBMRegressor(max_depth = None, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "# ExtraTreesRegressor 파라미터\n",
    "extratree_params = {\n",
    "    'n_estimators': 300,\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'max_features': 1.0,\n",
    "    'max_leaf_nodes': None,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'bootstrap': False,\n",
    "    'oob_score': False,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 0,\n",
    "    'verbose': 0,\n",
    "    'warm_start': False,\n",
    "    'ccp_alpha': 0.0,\n",
    "    'max_samples': None\n",
    "}\n",
    "\n",
    "# VotingRegressor 설정\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('lgbm', lgbm),\n",
    "    ('extratree', ExtraTreesRegressor(**extratree_params))\n",
    "])\n",
    "\n",
    "# VotingRegressor 평가\n",
    "voting_scores = cross_val_score(voting_regressor, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=2)\n",
    "voting_rmse_scores = np.sqrt(-voting_scores)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(voting_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6e040",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "train_target = housing_train[\"price\"]\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['1'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train = housing_train.drop(\"date\", axis=1)\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "# LGBMRegressor 파라미터\n",
    "lgbm_params = {'max_depth' : None, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'n_estimators': 100,\n",
    "             'bagging_fraction': 0.1, 'min_gain_to_split': 1, 'Task': 1,\n",
    "             'application': 'regression','num_boost_round': 790,'learning_rate': 0.1155, \n",
    "             'num_leaves': 31 ,'random_state': 0}\n",
    "\n",
    "# RandomForestRegressor 파라미터\n",
    "randomforest_params = {'n_estimators': 300, 'criterion': 'squared_error', 'max_depth': None, 'min_samples_split': 2,\n",
    "                       'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 1.0, 'max_leaf_nodes': None,\n",
    "                       'min_impurity_decrease': 0.0, 'bootstrap': True, 'oob_score': False, 'n_jobs': -1, 'random_state': 0,\n",
    "                       'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.0, 'max_samples': None\n",
    "}\n",
    "\n",
    "# VotingRegressor 설정\n",
    "voting_regressor_rf = VotingRegressor(estimators=[\n",
    "    ('lgbm', LGBMRegressor(**lgbm_params)),\n",
    "    ('randomforest', RandomForestRegressor(**randomforest_params))\n",
    "])\n",
    "\n",
    "# VotingRegressor 평가\n",
    "voting_scores_rf = cross_val_score(voting_regressor_rf, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "voting_rmse_scores_rf = np.sqrt(-voting_scores_rf)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(voting_rmse_scores_rf)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b20822",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "train_target = housing_train[\"price\"]\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['1'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train = housing_train.drop(\"date\", axis=1)\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "# LGBMRegressor 그리드 서치 대상 파라미터\n",
    "lgbm_param_grid_overfit = {\n",
    "    'max_depth': [None, 200, 500, 700],\n",
    "    'num_leaves': [45, 50, 55, 200],\n",
    "    'learning_rate': [0.1, 0.05, 0.03, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# ExtraTreesRegressor 그리드 서치 대상 파라미터\n",
    "extratree_param_grid_overfit = {\n",
    "    'n_estimators': [500, 800, 1000, 1200],\n",
    "    'max_depth': [None, 50, 100, 200],\n",
    "    'min_samples_split': [2, 10, 30],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# LGBMRegressor 그리드 서치 수행\n",
    "lgbm_grid_search_overfit = GridSearchCV(LGBMRegressor(), lgbm_param_grid_overfit, cv=10, scoring='neg_mean_squared_error', n_jobs=4, verbose=2)\n",
    "lgbm_grid_search_overfit.fit(sh_t_data, sh_t_target)\n",
    "\n",
    "# ExtraTreesRegressor 그리드 서치 수행\n",
    "extratree_grid_search_overfit = GridSearchCV(ExtraTreesRegressor(), extratree_param_grid_overfit, cv=10, scoring='neg_mean_squared_error', n_jobs=4, verbose=2)\n",
    "extratree_grid_search_overfit.fit(sh_t_data, sh_t_target)\n",
    "\n",
    "# LGBMRegressor와 ExtraTreesRegressor의 최적 모델을 가져와 VotingRegressor 생성\n",
    "best_lgbm = lgbm_grid_search_overfit.best_estimator_\n",
    "best_extratree = extratree_grid_search_overfit.best_estimator_\n",
    "\n",
    "voting_regressor = VotingRegressor(estimators=[('lgbm', best_lgbm), ('extratree', best_extratree)])\n",
    "\n",
    "# VotingRegressor 평가\n",
    "voting_scores = cross_val_score(voting_regressor, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=4, verbose=2)\n",
    "voting_rmse_scores = np.sqrt(-voting_scores)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"VotingRegressor Best Parameters for Overfitting:\")\n",
    "print(\"LGBMRegressor:\", lgbm_grid_search_overfit.best_params_)\n",
    "print(\"ExtraTreesRegressor:\", extratree_grid_search_overfit.best_params_)\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(voting_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704752dd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "train_target = housing_train[\"price\"]\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['1'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "\n",
    "housing_train = housing_train.drop(\"date\", axis=1)\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = None, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90d14b7",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "ordinal_encoder = OrdinalEncoder() #각 범주를 대응하는 숫자로 변환\n",
    "\n",
    "train_target = housing_train[\"price\"]\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['1'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "housing_train['sqft_living+bathrooms'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "# housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "# housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "# housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "# housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Totalviews//'] = housing_train['view'] // housing_train['waterfront']\n",
    "\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "housing_train = housing_train.drop(\"date\", axis=1)\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") #클래스를 중간값 채우기로 설정\n",
    "imputer.fit(housing_train)\n",
    "\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns = housing_train.columns, index=housing_train.index)\n",
    "\n",
    "filtered_train_data = housing_train\n",
    "filtered_train_data = filtered_train_data.drop(\"price\", axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(filtered_train_data)\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=filtered_train_data.columns)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = None, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155, \n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a859ed",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 데이터 불러오기\n",
    "input_file = \"kc_house_data.csv\"\n",
    "housing_train = pd.read_csv(input_file)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "train_target = housing_train[\"price\"]\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "\n",
    "# 특성 공학\n",
    "housing_train['1'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['house_age'] = 2023 - housing_train['yr_built']\n",
    "housing_train['years_since_renovation'] = 2023 - housing_train['yr_renovated']\n",
    "housing_train['indoor_to_outdoor_ratio'] = housing_train['sqft_living'] / housing_train['sqft_lot']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['bedrooms_to_bathrooms_ratio'] = housing_train['bedrooms'] / housing_train['bathrooms']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "\n",
    "# Ordinal Encoding\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "housing_train['sqft_living+bathrooms'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "\n",
    "housing_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 결측치 처리\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(housing_train)\n",
    "X = imputer.transform(housing_train)\n",
    "housing_train = pd.DataFrame(X, columns=housing_train.columns, index=housing_train.index)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "scalers = scaler.fit_transform(housing_train.drop(\"price\", axis=1))\n",
    "filtered_train_data = pd.DataFrame(scalers, columns=housing_train.columns[1:])\n",
    "\n",
    "# 데이터 섞기\n",
    "seed = 21345\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "# LightGBM 모델 초기화\n",
    "lgbm = LGBMRegressor(\n",
    "    max_depth=None, min_data_in_leaf=20, feature_fraction=1.0, n_estimators=100,\n",
    "    bagging_fraction=0.1, min_gain_to_split=1, Task=1,\n",
    "    application='regression', num_boost_round=790, learning_rate=0.1155,\n",
    "    num_leaves=31, random_state=0\n",
    ")\n",
    "\n",
    "# 교차 검증 수행\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c71eabf",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "tt = pd.read_csv('kc_house_data.csv')\n",
    "\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(housing_train)\n",
    "\n",
    "housing_train['sqft_living+bathrooms'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Totalviews//'] = housing_train['view'] // housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "housing_train['(sqft_living//waterfront/sqft_living)'] = ((housing_train['sqft_living']))//(housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train['((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = housing_train['(sqft_living//waterfront/sqft_living)']//housing_train['(waterfront//waterfront/sqft_living)']\n",
    "housing_train['(waterfront/waterfront/sqft_living)'] = (housing_train['waterfront']/housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(sqft_living**2)//(waterfront/waterfront/sqft_living)'] = (housing_train['sqft_living']**2)//(housing_train['(waterfront/waterfront/sqft_living)'])\n",
    "housing_train['(waterfront//(waterfront/sqft_living))'] = housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = ((housing_train['sqft_living']) // ((housing_train['(sqft_living//waterfront/sqft_living)'])) // (housing_train['(waterfront//waterfront/sqft_living)']))\n",
    "housing_train['(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))'] = housing_train['(waterfront//waterfront/sqft_living)'] / housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))']\n",
    "housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'] = ((housing_train['sqft_living']**2)//(housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])))\n",
    "housing_train['(((waterfront//waterfront/sqft_living))/((((waterfront//waterfront/sqft_living))//(((sqft_living**2)//(waterfront//(waterfront/sqft_living)))))))']= (((housing_train['(waterfront//waterfront/sqft_living)'])/((((housing_train['(waterfront//waterfront/sqft_living)']))//(housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'])))))\n",
    "housing_train['((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = housing_train['(sqft_living//waterfront/sqft_living)']//housing_train['(waterfront//waterfront/sqft_living)']\n",
    "housing_train['(waterfront//(waterfront/sqft_living))'] = housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])\n",
    "filtered_train_data = housing_train.drop(['(waterfront//waterfront/sqft_living)', '(waterfront/waterfront/sqft_living)', '(sqft_living**2)//(waterfront/waterfront/sqft_living)', '(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', '(sqft_living//waterfront/sqft_living)'], axis=1)\n",
    "filtered_train_data = filtered_train_data.drop(['price', 'tr_year'], axis=1)\n",
    "filtered_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "seed = 21345\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth=None, min_data_in_leaf=20, feature_fraction=1.0, n_estimators=100,\n",
    "                     bagging_fraction=0.1, min_gain_to_split=1, Task=1,\n",
    "                     application='regression', num_boost_round=790, learning_rate=0.1155,\n",
    "                     num_leaves=31, random_state=0)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0370f1",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(housing_train)\n",
    "\n",
    "housing_train['sqft_living+bathrooms'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Totalviews//'] = housing_train['view'] // housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "housing_train['(sqft_living//waterfront/sqft_living)'] = ((housing_train['sqft_living']))//(housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train[\"sqft_living//waterfront\"] = housing_train[\"sqft_living\"] // housing_train[\"waterfront\"]\n",
    "housing_train[\"waterfront/sqft_living\"] = housing_train[\"waterfront\"] // housing_train[\"sqft_living\"]\n",
    "housing_train['3/(waterfront/sqft_living)'] = 3/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train['2/(waterfront/sqft_living)'] = 2/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train['1/(waterfront/sqft_living)'] = 1/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train[\"sqft_living*waterfront\"] = housing_train[\"sqft_living\"] * housing_train[\"waterfront\"]\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train['((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = housing_train['(sqft_living//waterfront/sqft_living)']//housing_train['(waterfront//waterfront/sqft_living)']\n",
    "housing_train['(waterfront/waterfront/sqft_living)'] = (housing_train['waterfront']/housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(sqft_living**2)//(waterfront/waterfront/sqft_living)'] = (housing_train['sqft_living']**2)//(housing_train['(waterfront/waterfront/sqft_living)'])\n",
    "housing_train['(waterfront//(waterfront/sqft_living))'] = housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])#(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living)) ## 89.7\n",
    "housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = ((housing_train['sqft_living']) // ((housing_train['(sqft_living//waterfront/sqft_living)'])) // (housing_train['(waterfront//waterfront/sqft_living)']))\n",
    "housing_train['(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))'] = housing_train['(waterfront//waterfront/sqft_living)'] / housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))']\n",
    "housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'] = ((housing_train['sqft_living']**2)//(housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])))\n",
    "housing_train['(((waterfront//waterfront/sqft_living))/((((waterfront//waterfront/sqft_living))//(((sqft_living**2)//(waterfront//(waterfront/sqft_living)))))))']= (((housing_train['(waterfront//waterfront/sqft_living)'])/((((housing_train['(waterfront//waterfront/sqft_living)']))//(housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'])))))\n",
    "\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living**2)//(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//(waterfront/sqft_living))', axis=1)\n",
    "\n",
    "filtered_train_data = housing_train.drop('price', axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_year', axis=1)\n",
    "\n",
    "filtered_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# # k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "lgbm = LGBMRegressor(max_depth = None, min_data_in_leaf = 20, feature_fraction = 1.0, n_estimators=100,\n",
    "                     bagging_fraction = 0.1, min_gain_to_split = 1, Task = 1,\n",
    "                     application = 'regression',num_boost_round = 790,learning_rate = 0.1155,\n",
    "                     num_leaves = 31 ,random_state=0)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv = 10, n_jobs=-1)\n",
    "lgbm_rmse_scores = np.sqrt(-lgbm_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(lgbm_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca566cfb",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(housing_train)\n",
    "\n",
    "housing_train['sqft_living+bathrooms'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Totalviews//'] = housing_train['view'] // housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "housing_train['(sqft_living//waterfront/sqft_living)'] = ((housing_train['sqft_living']))//(housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train[\"sqft_living//waterfront\"] = housing_train[\"sqft_living\"] // housing_train[\"waterfront\"]\n",
    "housing_train[\"waterfront/sqft_living\"] = housing_train[\"waterfront\"] // housing_train[\"sqft_living\"]\n",
    "housing_train['3/(waterfront/sqft_living)'] = 3/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train['2/(waterfront/sqft_living)'] = 2/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train['1/(waterfront/sqft_living)'] = 1/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train[\"sqft_living*waterfront\"] = housing_train[\"sqft_living\"] * housing_train[\"waterfront\"]\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train['((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = housing_train['(sqft_living//waterfront/sqft_living)']//housing_train['(waterfront//waterfront/sqft_living)']\n",
    "housing_train['(waterfront/waterfront/sqft_living)'] = (housing_train['waterfront']/housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(sqft_living**2)//(waterfront/waterfront/sqft_living)'] = (housing_train['sqft_living']**2)//(housing_train['(waterfront/waterfront/sqft_living)'])\n",
    "housing_train['(waterfront//(waterfront/sqft_living))'] = housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])#(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living)) ## 89.7\n",
    "housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = ((housing_train['sqft_living']) // ((housing_train['(sqft_living//waterfront/sqft_living)'])) // (housing_train['(waterfront//waterfront/sqft_living)']))\n",
    "housing_train['(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))'] = housing_train['(waterfront//waterfront/sqft_living)'] / housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))']\n",
    "housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'] = ((housing_train['sqft_living']**2)//(housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])))\n",
    "housing_train['(((waterfront//waterfront/sqft_living))/((((waterfront//waterfront/sqft_living))//(((sqft_living**2)//(waterfront//(waterfront/sqft_living)))))))']= (((housing_train['(waterfront//waterfront/sqft_living)'])/((((housing_train['(waterfront//waterfront/sqft_living)']))//(housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'])))))\n",
    "\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living**2)//(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//(waterfront/sqft_living))', axis=1)\n",
    "\n",
    "filtered_train_data = housing_train.drop('price', axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_year', axis=1)\n",
    "\n",
    "filtered_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# # k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21345\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "catboost = CatBoostRegressor(depth=7, learning_rate=0.1, n_estimators=1100, verbose=0)\n",
    "\n",
    "catboost_scores = cross_val_score(catboost, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "catboost_rmse_scores = np.sqrt(-catboost_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(catboost_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1629f6d2",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(housing_train)\n",
    "\n",
    "housing_train['sqft_living+bathrooms'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Totalviews//'] = housing_train['view'] // housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "housing_train['(sqft_living//waterfront/sqft_living)'] = ((housing_train['sqft_living']))//(housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train[\"sqft_living//waterfront\"] = housing_train[\"sqft_living\"] // housing_train[\"waterfront\"]\n",
    "housing_train[\"waterfront/sqft_living\"] = housing_train[\"waterfront\"] // housing_train[\"sqft_living\"]\n",
    "housing_train['3/(waterfront/sqft_living)'] = 3/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train['2/(waterfront/sqft_living)'] = 2/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train['1/(waterfront/sqft_living)'] = 1/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train[\"sqft_living*waterfront\"] = housing_train[\"sqft_living\"] * housing_train[\"waterfront\"]\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train['((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = housing_train['(sqft_living//waterfront/sqft_living)']//housing_train['(waterfront//waterfront/sqft_living)']\n",
    "housing_train['(waterfront/waterfront/sqft_living)'] = (housing_train['waterfront']/housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(sqft_living**2)//(waterfront/waterfront/sqft_living)'] = (housing_train['sqft_living']**2)//(housing_train['(waterfront/waterfront/sqft_living)'])\n",
    "housing_train['(waterfront//(waterfront/sqft_living))'] = housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])#(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living)) ## 89.7\n",
    "housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = ((housing_train['sqft_living']) // ((housing_train['(sqft_living//waterfront/sqft_living)'])) // (housing_train['(waterfront//waterfront/sqft_living)']))\n",
    "housing_train['(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))'] = housing_train['(waterfront//waterfront/sqft_living)'] / housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))']\n",
    "housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'] = ((housing_train['sqft_living']**2)//(housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])))\n",
    "housing_train['(((waterfront//waterfront/sqft_living))/((((waterfront//waterfront/sqft_living))//(((sqft_living**2)//(waterfront//(waterfront/sqft_living)))))))']= (((housing_train['(waterfront//waterfront/sqft_living)'])/((((housing_train['(waterfront//waterfront/sqft_living)']))//(housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'])))))\n",
    "\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living**2)//(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//(waterfront/sqft_living))', axis=1)\n",
    "\n",
    "filtered_train_data = housing_train.drop('price', axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_year', axis=1)\n",
    "\n",
    "filtered_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# # k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21378\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "# CatBoostRegressor 초기화\n",
    "catboost = CatBoostRegressor(depth=7, learning_rate=0.1, verbose=0)\n",
    "\n",
    "# 교차 검증 수행\n",
    "best_model_scores = cross_val_score(catboost, sh_t_data, sh_t_target, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n",
    "best_model_rmse_scores = np.sqrt(-best_model_scores)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=======================================================================================\")\n",
    "# print(f\"{i}\")\n",
    "display_scores(best_model_rmse_scores)\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ece77",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(housing_train)\n",
    "\n",
    "housing_train['sqft_living+bathrooms'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Totalviews//'] = housing_train['view'] // housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "housing_train['(sqft_living//waterfront/sqft_living)'] = ((housing_train['sqft_living']))//(housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train[\"sqft_living//waterfront\"] = housing_train[\"sqft_living\"] // housing_train[\"waterfront\"]\n",
    "housing_train[\"waterfront/sqft_living\"] = housing_train[\"waterfront\"] // housing_train[\"sqft_living\"]\n",
    "housing_train['3/(waterfront/sqft_living)'] = 3/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train['2/(waterfront/sqft_living)'] = 2/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train['1/(waterfront/sqft_living)'] = 1/housing_train[\"waterfront/sqft_living\"]\n",
    "housing_train[\"sqft_living*waterfront\"] = housing_train[\"sqft_living\"] * housing_train[\"waterfront\"]\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train['((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = housing_train['(sqft_living//waterfront/sqft_living)']//housing_train['(waterfront//waterfront/sqft_living)']\n",
    "housing_train['(waterfront/waterfront/sqft_living)'] = (housing_train['waterfront']/housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(sqft_living**2)//(waterfront/waterfront/sqft_living)'] = (housing_train['sqft_living']**2)//(housing_train['(waterfront/waterfront/sqft_living)'])\n",
    "housing_train['(waterfront//(waterfront/sqft_living))'] = housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])#(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living)) ## 89.7\n",
    "housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = ((housing_train['sqft_living']) // ((housing_train['(sqft_living//waterfront/sqft_living)'])) // (housing_train['(waterfront//waterfront/sqft_living)']))\n",
    "housing_train['(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))'] = housing_train['(waterfront//waterfront/sqft_living)'] / housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))']\n",
    "housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'] = ((housing_train['sqft_living']**2)//(housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])))\n",
    "housing_train['(((waterfront//waterfront/sqft_living))/((((waterfront//waterfront/sqft_living))//(((sqft_living**2)//(waterfront//(waterfront/sqft_living)))))))']= (((housing_train['(waterfront//waterfront/sqft_living)'])/((((housing_train['(waterfront//waterfront/sqft_living)']))//(housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'])))))\n",
    "\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living**2)//(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//(waterfront/sqft_living))', axis=1)\n",
    "\n",
    "filtered_train_data = housing_train.drop('price', axis=1)\n",
    "filtered_train_data = filtered_train_data.drop('tr_year', axis=1)\n",
    "\n",
    "filtered_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# # k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21378\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "catboost = CatBoostRegressor(depth=7, learning_rate=0.1, n_estimators=1100, verbose=0)\n",
    "\n",
    "catboost_scores = cross_val_score(catboost, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "catboost_rmse_scores = np.sqrt(-catboost_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(catboost_rmse_scores)\n",
    "print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1998063a",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 데이터 불러오기\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "# OrdinalEncoder를 사용하여 범주형 변수를 숫자로 변환\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "# StandardScaler를 사용하여 수치형 변수를 표준화\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(housing_train)\n",
    "\n",
    "# 특성 엔지니어링\n",
    "housing_train['sqft_living+bathrooms'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Totalviews//'] = housing_train['view'] // housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "housing_train['(sqft_living//waterfront/sqft_living)'] = ((housing_train['sqft_living']))//(housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train[\"sqft_living*waterfront\"] = housing_train[\"sqft_living\"] * housing_train[\"waterfront\"]\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train['((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = housing_train['(sqft_living//waterfront/sqft_living)']//housing_train['(waterfront//waterfront/sqft_living)']\n",
    "housing_train['(waterfront/waterfront/sqft_living)'] = (housing_train['waterfront']/housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(sqft_living**2)//(waterfront/waterfront/sqft_living)'] = (housing_train['sqft_living']**2)//(housing_train['(waterfront/waterfront/sqft_living)'])\n",
    "housing_train['(waterfront//(waterfront/sqft_living))'] = housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])  # (sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))\n",
    "housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = ((housing_train['sqft_living']) // ((housing_train['(sqft_living//waterfront/sqft_living)'])) // (housing_train['(waterfront//waterfront/sqft_living)']))\n",
    "housing_train['(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))'] = housing_train['(waterfront//waterfront/sqft_living)'] / housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))']\n",
    "housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'] = ((housing_train['sqft_living']**2)//(housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])))\n",
    "housing_train['(((waterfront//waterfront/sqft_living))/((((waterfront//waterfront/sqft_living))//(((sqft_living**2)//(waterfront//(waterfront/sqft_living)))))))']= (((housing_train['(waterfront//waterfront/sqft_living)'])/((((housing_train['(waterfront//waterfront/sqft_living)']))//(housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'])))))\n",
    "\n",
    "# 불필요한 열 삭제\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living**2)//(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//(waterfront/sqft_living))', axis=1)\n",
    "\n",
    "# 목표 변수를 제외한 특성 데이터 생성\n",
    "filtered_train_data = housing_train.drop('price', axis=1)\n",
    "filtered_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21366\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "# CatBoost 모델 초기화\n",
    "catboost = CatBoostRegressor(depth=7, learning_rate=0.1, n_estimators=1100, verbose=0)\n",
    "\n",
    "# 교차 검증 수행\n",
    "catboost_scores = cross_val_score(catboost, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "catboost_rmse_scores = np.sqrt(-catboost_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(catboost_rmse_scores)\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa694d",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9461dd41",
   "metadata": {},
   "source": [
    "# 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "906edad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================================\n",
      "Scores: [122348.05952307  94499.35636369 117007.53506535  83628.8717908\n",
      " 105830.95531101 121477.34595344 105426.34835928  96323.97220175\n",
      " 106788.33147607 111901.67908371]\n",
      "Mean: 106523.24551281861\n",
      "Standard deviation: 11778.802518379614\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 데이터 불러오기\n",
    "housing_train = pd.read_csv('kc_house_data.csv')\n",
    "housing_train = housing_train.drop(\"id\", axis=1)\n",
    "train_target = housing_train[\"price\"].copy()\n",
    "\n",
    "# OrdinalEncoder를 사용하여 범주형 변수를 숫자로 변환\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_train['date'] = pd.to_datetime(housing_train['date'])\n",
    "housing_train[\"tr_year\"] = housing_train[\"date\"].dt.year\n",
    "housing_train[\"tr_month\"] = housing_train[\"date\"].dt.month\n",
    "housing_train[\"tr_day_name\"] = housing_train[\"date\"].dt.day_name\n",
    "housing_train[\"date\"] = housing_train[\"date\"].dt.strftime('%Y-%m')\n",
    "housing_train[\"tr_year\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_year\"]])\n",
    "housing_train[\"tr_month\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_month\"]])\n",
    "housing_train[\"tr_day_name\"] = ordinal_encoder.fit_transform(housing_train[[\"tr_day_name\"]])\n",
    "housing_train[\"date\"] = ordinal_encoder.fit_transform(housing_train[[\"date\"]])\n",
    "\n",
    "# StandardScaler를 사용하여 수치형 변수를 표준화\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(housing_train)\n",
    "\n",
    "# 특성 엔지니어링\n",
    "housing_train['sqft_living+bathrooms'] = housing_train['sqft_living'] + housing_train['bathrooms']\n",
    "housing_train['basement_to_living_ratio'] = housing_train['sqft_basement'] / housing_train['sqft_living']\n",
    "housing_train['location'] = housing_train['lat'] + housing_train['long']\n",
    "housing_train['living_to_floors_ratio'] = housing_train['sqft_living'] / housing_train['floors']\n",
    "housing_train['Totalviews'] = housing_train['view'] + housing_train['waterfront']\n",
    "housing_train['Totalviews//'] = housing_train['view'] // housing_train['waterfront']\n",
    "housing_train['Toalsizes'] = housing_train['sqft_living'] + housing_train['sqft_above'] + housing_train['sqft_basement'] + housing_train['sqft_living15']\n",
    "housing_train[\"house_per_sqft_livings\"] = 1 / (housing_train[\"sqft_living\"] + housing_train[\"sqft_living15\"])\n",
    "housing_train['(sqft_living*grade)/2'] = (housing_train['sqft_living'] * housing_train['grade']) / 2\n",
    "housing_train['(sqft_living//waterfront/sqft_living)'] = ((housing_train['sqft_living']))//(housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train[\"sqft_living*waterfront\"] = housing_train[\"sqft_living\"] * housing_train[\"waterfront\"]\n",
    "housing_train['(waterfront//waterfront/sqft_living)'] = (housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living']))\n",
    "housing_train['((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = housing_train['(sqft_living//waterfront/sqft_living)']//housing_train['(waterfront//waterfront/sqft_living)']\n",
    "housing_train['(waterfront/waterfront/sqft_living)'] = (housing_train['waterfront']/housing_train['waterfront']/housing_train['sqft_living'])\n",
    "housing_train['(sqft_living**2)//(waterfront/waterfront/sqft_living)'] = (housing_train['sqft_living']**2)//(housing_train['(waterfront/waterfront/sqft_living)'])\n",
    "housing_train['(waterfront//(waterfront/sqft_living))'] = housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])  # (sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))\n",
    "housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))'] = ((housing_train['sqft_living']) // ((housing_train['(sqft_living//waterfront/sqft_living)'])) // (housing_train['(waterfront//waterfront/sqft_living)']))\n",
    "housing_train['(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))'] = housing_train['(waterfront//waterfront/sqft_living)'] / housing_train['(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))']\n",
    "housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'] = ((housing_train['sqft_living']**2)//(housing_train['waterfront']//(housing_train['waterfront']/housing_train['sqft_living'])))\n",
    "housing_train['(((waterfront//waterfront/sqft_living))/((((waterfront//waterfront/sqft_living))//(((sqft_living**2)//(waterfront//(waterfront/sqft_living)))))))']= (((housing_train['(waterfront//waterfront/sqft_living)'])/((((housing_train['(waterfront//waterfront/sqft_living)']))//(housing_train['((sqft_living**2)//(waterfront//(waterfront/sqft_living)))'])))))\n",
    "\n",
    "# 불필요한 열 삭제\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living**2)//(waterfront/waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//waterfront/sqft_living/(sqft_living//((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))))', axis=1)\n",
    "housing_train = housing_train.drop('(sqft_living//waterfront/sqft_living)', axis=1)\n",
    "housing_train = housing_train.drop('((sqft_living//waterfront/sqft_living)//(waterfront//waterfront/sqft_living))', axis=1)\n",
    "housing_train = housing_train.drop('(waterfront//(waterfront/sqft_living))', axis=1)\n",
    "\n",
    "# 목표 변수를 제외한 특성 데이터 생성\n",
    "filtered_train_data = housing_train.drop('price', axis=1)\n",
    "filtered_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# k-폴드 CV의 평균을 계산하기 위한 함수\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21366\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "sh_in = np.random.permutation(len(filtered_train_data))\n",
    "sh_t_data = filtered_train_data.values[sh_in]\n",
    "sh_t_target = train_target.values[sh_in]\n",
    "\n",
    "# CatBoost 모델 초기화\n",
    "catboost = CatBoostRegressor(depth=7, learning_rate=0.1, n_estimators=2000, verbose=0)\n",
    "\n",
    "# 교차 검증 수행\n",
    "catboost_scores = cross_val_score(catboost, sh_t_data, sh_t_target, scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "catboost_rmse_scores = np.sqrt(-catboost_scores)\n",
    "\n",
    "print(\"=======================================================================================\")\n",
    "display_scores(catboost_rmse_scores)\n",
    "print(\"=======================================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ae4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
